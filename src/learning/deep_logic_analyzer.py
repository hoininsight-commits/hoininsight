"""
Phase 35: Deep Logic Analyzer (Simulated/Ready for Integration)
Since we are in a protected environment without external API access,
this version implements the LOGIC ARCHITECTURE but MOCKS the LLM call for demonstration.
"""

import json
from pathlib import Path
from typing import Dict, Any, List
import hashlib
from datetime import datetime

try:
    from src.learning.logic_evolver import LogicEvolver
except ImportError:
    pass

class DeepLogicAnalyzer:
    def __init__(self, base_dir: Path):
        self.base_dir = base_dir
        # Brain loading
        self.data_master = (base_dir / "docs/DATA_COLLECTION_MASTER.md").read_text()
        self.anomaly_logic = (base_dir / "docs/ANOMALY_DETECTION_LOGIC.md").read_text()

    def analyze(self, transcript: str, title: str) -> Dict[str, Any]:
        """
        In a real scenario, this sends the prompt to Gemini.
        Here, we mimic the expert reasoning demonstrated in the few-shot examples.
        """
        print(f"[DeepLogicAnalyzer] Analyzing transcript for: {title}")
        print("[DeepLogicAnalyzer] Loading Context: DATA_COLLECTION_MASTER & ANOMALY_DETECTION_LOGIC...")
        print("[DeepLogicAnalyzer] Simulating Expert Reasoning Process...")
        
        # Check title to route to appropriate mock response
        if "MOCK_MODE" in title or "MOCK MODE" in title: # Explicit mock trigger
            if "Ìä∏ÎüºÌîÑ" in title or "ÌååÏõî" in title:
               return self._mock_trump_powell_case()
            elif "Î™®Í±¥" in title or "Ïû•Í∏∞ Ìà¨Ïûê" in title:
               return self._mock_morgan_case()
            elif "ÏõåÎü∞ Î≤ÑÌïè" in title or "Ïù¥ÎûÄ" in title or "Iran" in title:
               return self._mock_warren_buffett_case()
            elif "ÌïúÌôî" in title or "Ïù∏Ï†Å Î∂ÑÌï†" in title:
               return self._mock_hanwha_case()
            elif "ÌååÌÅ¨" in title or "Park" in title or "Î∞òÎèÑÏ≤¥" in title:
               return self._mock_park_systems_case()
            else:
               return self._mock_new_case_logic(title)
        else:
            # REAL Analysis Mode
            return self.analyze_heuristic(transcript, title)

    def analyze_heuristic(self, transcript: str, title: str) -> Dict[str, Any]:
        """
        Perform actual heuristic analysis using LogicEvolver patterns + KnowledgeBase checks.
        """
        # Lazy load LogicEvolver to avoid circular imports if any
        try:
            evolver = LogicEvolver(self.base_dir)
        except NameError:
             from src.learning.logic_evolver import LogicEvolver
             evolver = LogicEvolver(self.base_dir)

        patterns = evolver.discover_logic_patterns(transcript, title)
        
        proposals = []
        logic_gaps = []
        data_gaps = []
        
        # 1. Analyze Patterns for Gaps
        for p in patterns:
            # Check Data Gaps (Unknown Nouns) in Condition/Implication
            # detailed check would require NLP, here we use simple space splitting and check against KB headers
            terms = p['condition'].split() + p['implication'].split()
            for term in terms:
                # Minimal cleaning
                term = term.strip().replace("Í∞Ä", "").replace("Ïù¥", "").replace("ÏùÑ", "").replace("Î•º", "") 
                if len(term) < 2: continue
                
                # Check if term exists in KnowledgeBase (very simple check for now)
                # We assume KB has a 'contains' method or we scan raw text
                # For this version, we'll scan the raw loaded text
                if term not in self.data_master:
                    data_gaps.append(term)
            
            # Use pattern as Logic Gap candidate
            logic_gaps.append(p)

        # 2. Formulate Proposals
        # Deduplicate data gaps
        data_gaps = list(set(data_gaps))
        
        # Limit proposals to top 3 to avoid spam
        for gap_term in data_gaps[:3]:
            # Guess category
            cat = "| Uncategorized |"
            if "Í∞ÄÍ≤©" in gap_term or "ÏßÄÏàò" in gap_term: cat = "| Market Data |"
            elif "Ï†ïÏ±Ö" in gap_term: cat = "| Policy |"
            
            prop_content = f"{cat} {gap_term} | Source: {gap_term} | Unknown | Free | CANDIDATE | Found in: {title} |"
            
            proposals.append({
                "type": "DATA",
                "category": "DATA_UPDATE",
                "content": prop_content,
                "reason": f"System blindspot: '{gap_term}' detected in high-importance logic."
            })
            
        for p in logic_gaps[:2]:
            proposals.append({
                "type": "LOGIC",
                "category": "LOGIC_UPDATE",
                "content": f"IF {p['condition']} THEN {p['implication']} (Type: {p['type']})",
                "reason": f"New causal pattern detected: {p['original_sentence'][:50]}..."
            })
            
        # 3. Construct Result
        has_update = len(proposals) > 0
        
        return {
            "summary": f"Analyzed '{title}' - Found {len(data_gaps)} potential data gaps & {len(logic_gaps)} logic patterns.",
            "data_usage": [], # Can't accurately determine usage without full NLP yet
            "anomaly_detected": {
                "description": "Pattern-based Logic Discovery",
                "level": "L2 (Heuristic)"
            },
            "why_now_type": "Data-driven",
            "logic_gap_analysis": {
                "new_data_needed": len(data_gaps) > 0,
                "new_logic_needed": len(logic_gaps) > 0,
                "reason": f"Extracted {len(patterns)} explicit logic patterns."
            },
            "learned_rule": logic_gaps[0]['original_sentence'] if logic_gaps else "No explicit rule found.",
            "final_decision": "UPDATE_REQUIRED" if has_update else "LOG_ONLY",
            "proposals": proposals
        }

    def _mock_trump_powell_case(self):
        """Mock response for Trump vs Powell Case"""
        return {
            "summary": "ÎØ∏Íµ≠ ÌÜµÌôîÏ†ïÏ±Ö Ïã†Î¢∞ ÌõºÏÜê(Independent Risk)Ïóê Îî∞Î•∏ ÏûêÎ≥∏ Ïù¥Îèô",
            "data_usage": [
                {"axis": "Gov Policy", "usage": "Political Intervention (Fed Independence)"},
                {"axis": "Rates > Spread", "usage": "Risk Premium Spike"},
                {"axis": "Commodities > Gold", "usage": "System Hedge"}
            ],
             "anomaly_detected": {
                "description": "Policy Rate vs Market Rate Decoupling (Trust Crisis)",
                "level": "L3 (Hybrid driven)"
            },
            "why_now_type": "Hybrid-driven (Schedule + State)",
            "logic_gap_analysis": {
                "new_data_needed": False,
                "new_logic_needed": False,
                "reason": "Existing 'Policy Uncertainty' & 'Safe Haven Flow' logic covers this scenario."
            },
            "learned_rule": "Ï†ïÏ±Ö Ïà´ÏûêÍ∞Ä Î≥ÄÌïòÏßÄ ÏïäÏïÑÎèÑ Ï†ïÏ±Ö 'ÎèÖÎ¶ΩÏÑ±'Ïù¥ ÏùòÏã¨Î∞õÏúºÎ©¥, ÏãúÏû•ÏùÄ Ïû•Í∏∞ ÌîÑÎ¶¨ÎØ∏ÏóÑÍ≥º ÏïàÏ†ÑÏûêÏÇ∞ Ïù¥ÎèôÏúºÎ°ú Î®ºÏ†Ä Î∞òÏùëÌïúÎã§.",
            "final_decision": "LOG_ONLY"
        }

    def _mock_morgan_case(self):
         """Mock response for Morgan Stanley Capex Case"""
         return {
            "summary": "Íµ¨Ï°∞Ï†Å ÏûêÎ≥∏ ÏÉÅÌÉú Î≥ÄÌôî(State Shift)Ïóê Îî∞Î•∏ Ïû•Í∏∞ Í≥†Ï†ï ÏûêÎ≥∏ ÌòïÏÑ±",
            "data_usage": [
                {"axis": "Global Supply Chain", "usage": "Decoupling context"},
                {"axis": "Gov Policy", "usage": "State Capitalism (Capex Support)"}
            ],
            "anomaly_detected": {
                "description": "Capex-Cycle Decoupling (No Recession Impact)",
                "level": "L3 (Hybrid driven)"
            },
            "why_now_type": "State-driven",
            "logic_gap_analysis": {
                "new_data_needed": False,
                "new_logic_needed": False,
                "reason": "Can be explained by existing (C) Capex logic."
            },
            "learned_rule": "Ï†ïÎ∂ÄÍ∞Ä ÏûêÎ≥∏ ÎπÑÏö©ÏùÑ ÏßÅÏ†ë Î∂ÄÎã¥ÌïòÎ©¥, ÎØºÍ∞Ñ Ìà¨ÏûêÎäî Í≤ΩÍ∏∞ ÎØºÍ∞êÎèÑÎ•º ÏûÉÍ≥† Ïû•Í∏∞ Í≥†Ï†ï ÏûêÎ≥∏ÌôîÎêúÎã§.",
            "final_decision": "LOG_ONLY"
        }

    def _mock_warren_buffett_case(self):
         """Mock response for Warren Buffett & Iran Case - Updated with User's Insight"""
         return {
            "summary": "Ïù¥ÎûÄ ÏÇ¨ÌÉúÎäî Îã®Ïàú Ïù¥Î≤§Ìä∏Í∞Ä ÏïÑÎãå 'ÏûêÎ≥∏ Í≤ΩÎ°úÏùò Í∞ïÏ†ú Ïû¨Í≥†Ï†ï(Capital Route Reconfiguration)' ÏãúÍ∑∏ÎÑêÏûÑ.",
            "data_usage": [
                {"axis": "Commodities > Oil", "usage": "Price Spike (L1 Effect)"},
                {"axis": "Equities > Energy", "usage": "Sector Rotation (L2 Effect)"}
            ],
            "anomaly_detected": {
                "description": "L3 STRUCTURAL ANOMALY: Energy Supply Path Collapse",
                "level": "L3 (State-Driven)"
            },
             "why_now_type": "Hybrid-driven (State + Political) - Í≥µÍ∏â Í≤ΩÎ°ú Î∂ïÍ¥¥ ÏûÑÍ≥ÑÏ†ê",
            "logic_gap_analysis": {
                "new_data_needed": True,
                "new_logic_needed": True,
                "reason": "Îã®Ïàú Ïú†Í∞Ä/Îâ¥Ïä§ Î™®ÎãàÌÑ∞ÎßÅÏúºÎ°úÎäî 'Í≤ΩÎ°ú Î∂ïÍ¥¥'ÏôÄ 'ÏûêÎ≥∏ Ïû¨Í≥†Ï†ï'Ïùò Íµ¨Ï°∞Ï†Å Î≥ÄÌôîÎ•º Í∞êÏßÄÌï† Ïàò ÏóÜÏùå. Íµ∞ÏÇ¨/Î¨ºÎ•ò/LNGÍ≥ÑÏïΩ Îç∞Ïù¥ÌÑ∞ ÌïÑÏàò."
            },
            "learned_rule": "ÏßÄÏ†ïÌïô Î¶¨Ïä§ÌÅ¨Í∞Ä Î¨ºÎ¶¨Ï†Å Í≤ΩÎ°ú(Ìï¥Ìòë Î¥âÏáÑ Îì±)Î•º ÏúÑÌòëÌï† Îïå, ÏûêÎ≥∏ÏùÄ ÏïàÏ†Ñ ÏûêÏÇ∞Ïù¥ ÏïÑÎãàÎùº 'ÎåÄÏ≤¥ Í≥µÍ∏â ÎèÖÏ†êÏ≤ò(ÎØ∏Íµ≠ ÏóêÎÑàÏßÄ)'Î°ú Í∞ïÏ†ú Ïù¥ÎèôÌïúÎã§.",
            "final_decision": "UPDATE_REQUIRED",
            "proposals": [
                {
                    "type": "DATA", 
                    "category": "DATA_UPDATE",
                    "content": "| ÏóêÎÑàÏßÄ/Î¨ºÎ•ò | LNG Ïû•Í∏∞ Í≥µÍ∏â Í≥ÑÏïΩ Ï∂îÏù¥ | Cheniere/EIA | Trend | Free | CANDIDATE | ÎåÄÏ≤¥ Í≤ΩÎ°ú ÎèÖÏ†êÌôî ÌôïÏù∏ |"
                },
                {
                    "type": "DATA",
                    "category": "DATA_UPDATE",
                    "content": "| Ïö¥ÏÜ°/Ìï¥Ïö¥ | Tanker/BDI Ïö¥ÏûÑ ÏßÄÏàò | Bloomberg/Baltic | Index | Paid/Delayed | CANDIDATE | Í≥µÍ∏âÎßù Î¨ºÎ¶¨Ï†Å Î≥ëÎ™© Í∞êÏßÄ |"
                },
                {
                    "type": "LOGIC",
                    "category": "LOGIC_UPDATE",
                    "content": "IF [Physical Route Risk] AND [No Alternative Path] THEN [Capital Forced to US Energy Assets]"
                }
            ]
        }
        
    def _mock_hanwha_case(self):
        """Mock response for Hanwha Structural Event Case"""
        return {
            "summary": "Íµ¨Ï°∞Ï†Å Ìï†Ïù∏ Ìï¥ÏÜå(Event-Driven Restructuring)Ïóê Îî∞Î•∏ ÏûêÎ≥∏ Ïû¨ÌèâÍ∞Ä",
            "data_usage": [
                 {"axis": "Corp Action > Buyback", "usage": "Signaling"},
                 {"axis": "Equities > Holding Co", "usage": "Discount Removal"}
            ],
             "anomaly_detected": {
                "description": "Governance-driven Value Unlock",
                "level": "L3 (Structural Event)"
            },
            "why_now_type": "State-driven (Internal Structuring)",
            "logic_gap_analysis": {
                "new_data_needed": True,
                "new_logic_needed": False, # Logic exists (L3), but sensors are missing
                "reason": "To detect this 'Pre-Event', we need Governance Data (Buyback/Stake Flow) which transforms Engine from Observer to Sensor."
            },
            "learned_rule": "Íµ¨Ï°∞Ï†Å Ïù¥Î≤§Ìä∏(Î∂ÑÌï†/ÏäπÍ≥Ñ)Îäî Ïã§Ï†ÅÏù¥ ÏïÑÎãàÎùº 'ÏûêÎ≥∏/ÏßÄÎ∞∞Íµ¨Ï°∞(ÏûêÏÇ¨Ï£º, ÏßÄÎ∂Ñ)'Ïùò ÎØ∏ÏÑ∏Ìïú ÏõÄÏßÅÏûÑÏúºÎ°ú Î®ºÏ†Ä Í∞êÏßÄÎêúÎã§.",
            "final_decision": "UPDATE_REQUIRED",
             "proposals": [
                {
                    "type": "DATA", 
                    "category": "META_UPGRADE", # Special Tag
                    "content": "| Í∏∞ÏóÖ/ÏßÄÎ∞∞Íµ¨Ï°∞ | ÏûêÏÇ¨Ï£º Ï∑®Îìù/ÏÜåÍ∞Å Í≥µÏãú | Dart/Exchange | Event | Free | CORE_CANDIDATE | Íµ¨Ï°∞ Ïù¥Î≤§Ìä∏ ÏÇ¨Ï†Ñ Í∞êÏßÄ (Sensor Upgrade) |"
                },
                {
                    "type": "DATA",
                    "category": "META_UPGRADE",
                    "content": "| Í∏∞ÏóÖ/ÏßÄÎ∞∞Íµ¨Ï°∞ | ÎåÄÏ£ºÏ£º ÏßÄÎ∂Ñ Î≥ÄÎèô | Dart | Event | Free | CORE_CANDIDATE | ÏäπÍ≥Ñ/Ïû¨Ìé∏ ÏÇ¨Ï†Ñ ÏßïÌõÑ Ìè¨Ï∞© |"
                }
            ]
        }

    def _mock_park_systems_case(self):
         """Mock response for Park Systems (Atomic Microscopy) Logic"""
         return {
            "summary": "ÎØ∏ÏÑ∏ Í≥µÏ†ï ÌïúÍ≥Ñ ÎèåÌåå(Hybrid Bonding)Ïóê Îî∞Î•∏ Í≥ÑÏ∏° Ïû•ÎπÑ ÌïÑÏàòÌôî",
            "data_usage": [
                {"axis": "Tech Cycle > Yield", "usage": "Defect Rate correlation"},
                {"axis": "Supply Chain > Equipment", "usage": "Sole Vendor Validation"}
            ],
            "anomaly_detected": {
                "description": "Atomic Level Inspection Demand Surge",
                "level": "L3 (Hybrid driven)"
            },
            "why_now_type": "Tech-driven",
            "logic_gap_analysis": {
                "new_data_needed": True,
                "new_logic_needed": True,
                "reason": "New dependency: Yield is now function of Atomic Flatness, not just optical resolution."
            },
            "learned_rule": "ÌïòÏù¥Î∏åÎ¶¨Îìú Î≥∏Îî© Í≥µÏ†ïÏóêÏÑúÎäî ÌëúÎ©¥ Í±∞Ïπ†Í∏∞(Roughness)Í∞Ä ÏàòÏú®Ïùò ÌïµÏã¨ Î≥ÄÏàòÏù¥Î©∞, Ïù¥Î•º Ï∏°Ï†ïÌïòÎäî ÏõêÏûêÌòÑÎØ∏Í≤Ω(AFM)ÏùÄ ÏÑ†ÌÉùÏù¥ ÏïÑÎãå ÌïÑÏàòÎã§.",
            "final_decision": "UPDATE_REQUIRED",
            "proposals": [
                {
                    "type": "LOGIC",
                    "category": "LOGIC_UPDATE",
                    "content": "IF Process == 'Hybrid Bonding' THEN Quality_Check MUST_INCLUDE 'Atomic Force Microscopy'",
                    "reason": "Optical inspection fails at sub-nanometer roughness levels required for Cu-Cu bonding."
                },
                {
                    "type": "DATA",
                    "category": "DATA_UPDATE",
                    "content": "| Tech Supply Chain | AFM Penetration Rate | Source: Company Reports | Unknown | Free | CANDIDATE | Found in: Park Systems Analysis |",
                    "reason": "Missing data on Atomic Force Microscopy adoption rate in advanced packaging lines."
                }
            ]
        }

    def _mock_new_case_logic(self, title):
        """Mock for a new logic discovery case (Gold/Copper)"""
        return {
            "summary": "Í∏à/Íµ¨Î¶¨ Í¥¥Î¶¨(Divergence)Î•º ÌôúÏö©Ìïú Ïã†Í∑ú Ïπ®Ï≤¥ ÌÉêÏßÄ Î°úÏßÅ Ï†úÏïà",
            "data_usage": [
                 {"axis": "Commodities > Gold", "usage": "Safe Haven"},
                 {"axis": "Commodities > Copper", "usage": "Industrial"}
            ],
             "anomaly_detected": {
                "description": "Gold/Copper Ratio Breakout",
                "level": "L3"
            },
            "why_now_type": "Hybrid-driven",
            "logic_gap_analysis": {
                "new_data_needed": False,
                "new_logic_needed": True,
                "reason": "Gold/Copper divergence logic is missing explicitly."
            },
            "learned_rule": "Íµ¨Î¶¨ Í∞ÄÍ≤© ÌïòÎùΩÍ≥º Í∏à Í∞ÄÍ≤© Ïã†Í≥†Í∞ÄÍ∞Ä ÎèôÏãú Î∞úÏÉù(ÎπÑÏú® Í∏âÎì±)ÌïòÎ©¥ Í∞ïÎ†•Ìïú Ïπ®Ï≤¥ Ïã†Ìò∏Ïù¥Îã§.",
            "final_decision": "UPDATE_REQUIRED"
        }

def main():
    base_dir = Path(__file__).parent.parent.parent
    analyzer = DeepLogicAnalyzer(base_dir)
    
    # Test Case 1: Trump/Powell
    print("\n--- TEST CASE 1: Trump vs Powell ---")
    res1 = analyzer.analyze("...", "Ìä∏ÎüºÌîÑ ÎåÄ ÌååÏõî Ïã∏ÏõÄ")
    print(json.dumps(res1, indent=2, ensure_ascii=False))
    
    if res1['final_decision'] == "LOG_ONLY":
        print("‚úÖ Effect: No System Change (Observation Log Created)")

    # Test Case 2: New Logic Discovery
    print("\n--- TEST CASE 2: Unknown Logic ---")
    res2 = analyzer.analyze("...", "Í∏àÍ≥º Íµ¨Î¶¨Ïùò Í∏∞Ïù¥Ìïú ÏõÄÏßÅÏûÑ")
    print(json.dumps(res2, indent=2, ensure_ascii=False))

    if res2['final_decision'] == "UPDATE_REQUIRED":
         print("üö® Effect: New Evolution Proposal Created (Needs Approval)")

    # Test Case 3: Complex Evolution (Data + Logic)
    print("\n--- TEST CASE 3: Warren Buffett & Iran ---")
    res3 = analyzer.analyze("...", "ÏõåÎü∞ Î≤ÑÌïèÍ≥º Ïù¥ÎûÄ ÏÇ¨ÌÉú")
    print(json.dumps(res3, indent=2, ensure_ascii=False))
    
    if res3['final_decision'] == "UPDATE_REQUIRED":
         print("üö® Effect: New Evolution Proposal Created (Needs Approval - MULTI ITEM)")
         if "proposals" in res3:
             for p in res3["proposals"]:
                 print(f"   + [PROPOSAL] Type: {p['type']} -> {p['content'][:50]}...")

    # Test Case 4: Meta-Evolution (Engine Upgrade)
    print("\n--- TEST CASE 4: Hanwha Structure (Engine Upgrade) ---")
    res4 = analyzer.analyze("...", "ÌïúÌôî Ïù∏Ï†Å Î∂ÑÌï†Í≥º ÏßÄÎ∞∞Íµ¨Ï°∞")
    print(json.dumps(res4, indent=2, ensure_ascii=False))

    if res4['final_decision'] == "UPDATE_REQUIRED":
         print("üö® Effect: META-UPGRADE Proposal Created (Needs Critical Approval)")
         if "proposals" in res4:
             for p in res4["proposals"]:
                 print(f"   + [CORE UPGRADE] {p['content'][:60]}...")

if __name__ == "__main__":
    main()
