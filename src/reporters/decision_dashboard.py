import json
from pathlib import Path
from typing import Dict, List, Any
import yaml
from dataclasses import dataclass, asdict

@dataclass
class DecisionCard:
    topic_id: str
    title: str
    status: str
    reason: str
    evidence_count: int
    raw_score: float
    flags: List[str]
    speak_pack: Dict[str, Any] = None
    evidence_refs: List[Dict[str, Any]] = None
    tags: List[str] = None
    why_today: str = None
    bridge_eligible: bool = False
    is_fact_driven: bool = False
    fact_why_now: str = None

class DecisionDashboard:
    """
    Renders human-readable Decision Dashboard from read-only outputs.
    """
    def __init__(self, base_dir: Path):
        self.base_dir = base_dir
        self.reason_map = self._load_reason_map()
        
    def _load_reason_map(self) -> Dict:
        path = self.base_dir / "registry/decision_reason_map_v1.yml"
        if not path.exists():
            return {}
        try:
            return yaml.safe_load(path.read_text(encoding="utf-8"))
        except:
            return {}

    def build_dashboard_data(self, ymd: str) -> Dict[str, Any]:
        """
        Aggregates data for the dashboard.
        """
        # 1. Load Gate Output
        gate_dir = self.base_dir / "data" / "topics" / "gate" / ymd.replace("-", "/")
        gate_out = gate_dir / "topic_gate_output.json"
        gate_cands = gate_dir / "topic_gate_candidates.json"
        
        # Load Candidates for Source Mapping
        cand_map = {}
        if gate_cands.exists():
            try:
                c_data = json.loads(gate_cands.read_text(encoding="utf-8"))
                for c in c_data.get("candidates", []):
                    cand_map[c.get("candidate_id")] = c
            except:
                pass

        topics = []
        if gate_out.exists():
            try:
                data = json.loads(gate_out.read_text(encoding="utf-8"))
                if isinstance(data, dict):
                    if "ranked" in data:
                        topics = data.get("ranked", [])
                    elif "top1" in data:
                        topics = [data["top1"]]
                    elif "topic_id" in data:
                        # Direct single topic object
                        topics = [data]
            except Exception as e:
                print(f"[Dashboard] Error parsing gate_out: {e}")
        
        cards = []
        status_counts = {"READY": 0, "HOLD": 0, "DROP": 0}
        failure_tally = {}
        flag_tally = {}
        
        # 2. Process each topic
        for t in topics:
            tid = t.get("topic_id")
            if not tid: continue
            
            # Find script sidecar
            # Pattern: script_v1_{tid}.md.quality.json
            quality_file = gate_dir / f"script_v1_{tid}.md.quality.json"
            
            status = "DROP" # Default if no script
            codes = ["NO_SCRIPT"]
            evidence_cnt = 0
            
            if quality_file.exists():
                try:
                    q_data = json.loads(quality_file.read_text(encoding="utf-8"))
                    status = q_data.get("quality_status", "DROP")
                    codes = q_data.get("failure_codes", [])
                    # Infer evidence count from script if possible, or assume based on status
                    evidence_cnt = self._count_evidence_from_script(gate_dir / f"script_v1_{tid}.md")
                except:
                    pass
            
            # Translate Reason
            reason_text = self._get_reason_text(status, codes)
            
            # Tally
            status_counts[status] = status_counts.get(status, 0) + 1
            for c in codes:
                failure_tally[c] = failure_tally.get(c, 0) + 1
            
            # Compute Flags
            flags = self._compute_flags(t, evidence_cnt)
            for f in flags:
                flag_tally[f] = flag_tally.get(f, 0) + 1

            # Build Speak Pack & Recommender (only for READY)
            speak_pack = None
            evidence_refs = None
            tags = None
            why_today = None
            
            if status == "READY":
                speak_pack = self._build_speak_pack(t, evidence_cnt, flags)
                evidence_refs = self._build_evidence_refs(t, cand_map)
                # Recommender Hints
                tags = self._compute_recommender_tags(t, flags)
                why_today = self._compute_why_today(t, speak_pack)

            cards.append(DecisionCard(
                topic_id=tid,
                title=t.get("title", "Untitled"),
                status=status,
                reason=reason_text,
                evidence_count=evidence_cnt,
                raw_score=t.get("total_score", 0.0),
                flags=flags,
                speak_pack=speak_pack,
                evidence_refs=evidence_refs,
                tags=tags,
                why_today=why_today,
                bridge_eligible=t.get("handoff_to_structural", False),
                is_fact_driven=self._check_fact_driven(t),
                fact_why_now=self._get_fact_why_now_hint(t) if self._check_fact_driven(t) else None
            ))
            
        # 3. Sort (Presentation Only)
        # Groups: READY -> HOLD -> DROP
        # Within: Score desc
        cards.sort(key=lambda x: (
            {"READY": 0, "HOLD": 1, "DROP": 2}.get(x.status, 3), 
            -x.raw_score
        ))
        
        # 4. "Why No Speak" Analysis
        no_speak_reason = []
        if status_counts["READY"] == 0:
            # Top 3 blockers
            sorted_fails = sorted(failure_tally.items(), key=lambda x: x[1], reverse=True)[:3]
            for code, count in sorted_fails:
                 # Translate code
                 desc = self._get_code_desc(status="DROP", code=code) # Assume DROP context for blockers
                 no_speak_reason.append(f"{desc} ({count}Í±¥)")
        
        return {
            "summary": status_counts,
            "cards": [asdict(c) for c in cards],
            "no_speak_analysis": no_speak_reason,
            "flag_summary": flag_tally,
            "has_fact_driven_candidate": any(c.is_fact_driven for c in cards if c.status != 'READY')
        }

    def render_markdown(self, data: Dict[str, Any]) -> str:
        lines = []
        cards = data.get("cards", [])
        
        # Partition Topics
        ready_topics = [c for c in cards if c['status'] == 'READY']
        hold_topics = [c for c in cards if c['status'] == 'HOLD']
        drop_topics = [c for c in cards if c['status'] == 'DROP']
        
        lines.append("\n## DECISION DASHBOARD (Beta)\n")
        
        # SCRIPT QUALITY Counters
        s = data.get("summary", {})
        lines.append(f"**SCRIPT QUALITY**: üü¢ READY={s.get('READY',0)} | üü° HOLD={s.get('HOLD',0)} | üî¥ DROP={s.get('DROP',0)}")
        
        # WHY NO SPEAK Panel (if needed)
        if not ready_topics:
            self._render_no_speak_panel(lines, data)
        
        # --- SECTION 1: TODAY - SPEAKABLE TOPICS ({len(ready_topics)}) ---
        lines.append(f"\n## üé¨ TODAY ‚Äî SPEAKABLE TOPICS ({len(ready_topics)})")
        lines.append("‚Äª ÏãúÏä§ÌÖúÏùÄ ÏÑ†ÌÉùÌïòÏßÄ ÏïäÏäµÎãàÎã§. ÏïÑÎûòÎäî Ïò§Îäò ÏÑ§Î™Ö Í∞ÄÎä•Ìïú ÌõÑÎ≥¥ ÏöîÏïΩÏûÖÎãàÎã§.")
        
        if not ready_topics:
            lines.append("- (No topics ready for broadcast today)")
        else:
            # Split Lanes
            anomaly_lane = [c for c in ready_topics if not c.get('is_fact_driven')]
            fact_lane = [c for c in ready_topics if c.get('is_fact_driven')]
            
            # A) ANOMALY-DRIVEN (Signal First)
            lines.append(f"\n### üì° A) ANOMALY-DRIVEN (Signal First)")
            if not anomaly_lane:
                lines.append("_No ANOMALY-DRIVEN signals today_")
            else:
                for c in anomaly_lane[:5]: 
                    lines.append(self._render_ready_card(c))
                if len(anomaly_lane) > 5:
                    lines.append("\n**Additional Anomaly Signals (Optional)**")
                    for c in anomaly_lane[5:]:
                        tags_str = " " + " ".join(c['tags']) if c.get('tags') else ""
                        lines.append(f"- {c['title']} (Evidence: {c['evidence_count']}){tags_str}")
            
            # B) FACT-DRIVEN (Fact First)
            lines.append(f"\n### üìë B) FACT-DRIVEN (Fact First)")
            if not fact_lane:
                lines.append("_No FACT-DRIVEN topics today_")
            else:
                for c in fact_lane[:5]:
                    lines.append(self._render_ready_card(c))
                if len(fact_lane) > 5:
                    lines.append("\n**Additional Fact Topics (Optional)**")
                    for c in fact_lane[5:]:
                        tags_str = " " + " ".join(c['tags']) if c.get('tags') else ""
                        lines.append(f"- {c['title']} (Evidence: {c['evidence_count']}){tags_str}")
        
        # --- ALMOST CANDIDATES ---
        self._render_almost_candidates(cards, lines)
        
        # --- SECTION 2: WATCHLIST - NOT YET (HOLD) ---
        lines.append(f"\n## üëÄ WATCHLIST ‚Äî NOT YET ({len(hold_topics)})")
        if not hold_topics:
            lines.append("- (No items on watchlist)")
        else:
            lines.append("| Status | Title | Why not speak yet? |")
            lines.append("|---|---|---|")
            for c in hold_topics:
                reason = self._get_hold_reason(c)
                lines.append(f"| ‚ö†Ô∏è HOLD | {c['title']} | {reason} |")
                
        # --- SECTION 3: ARCHIVE - DROP ---
        if drop_topics:
            lines.append(f"\n## üóëÔ∏è ARCHIVE ‚Äî DROP ({len(drop_topics)})")
            lines.append("<details><summary>Click to view dropped topics</summary>")
            lines.append("")
            lines.append("| Status | Title | Reason |")
            lines.append("|---|---|---|")
            for c in drop_topics:
                # Use simplified reason, remove internal codes if any leak
                r = c['reason'].replace("FAIL_HOOK", "Hook ÎØ∏Îã¨").replace("NO_EVIDENCE", "Ï¶ùÍ±∞ ÏóÜÏùå")
                lines.append(f"| ‚õî DROP | {c['title']} | {r} |")
            lines.append("</details>")

        return "\n".join(lines)

    def _render_no_speak_panel(self, lines: List[str], data: Dict[str, Any]):
        """Renders the detailed WHY NO SPEAK panel when READY=0."""
        # Aggregate failing reasons
        f_tally = data.get("flag_summary", {})
        # We also want specific failure codes from summary stats or detailed reasons
        # But aggregate is easier from the pre-calculated 'no_speak_analysis' if strictly codes.
        # However, prompt asks for "NO_EVIDENCE: N", "TITLE_MISMATCH: N" etc.
        # Let's combine flag_tally and top failure codes.
        
        lines.append("\n## üö´ WHY NO SPEAK (Today)")
        lines.append("> **Ïò§ÎäòÏùÄ ÏòÅÏÉÅÌôî Í∞ÄÎä•Ìïú ÌÜ†ÌîΩÏù¥ ÏóÜÏäµÎãàÎã§.** ÏïÑÎûò ÏÇ¨Ïú†Î°ú Ïù∏Ìï¥ Î≥¥Î•òÎêòÏóàÏäµÎãàÎã§.")
        lines.append("")
        
        # Merge lists
        reasons = {}
        # 1. From flags
        for f, cnt in f_tally.items():
            reasons[f] = cnt
            
        # 2. From failure codes (extracted from no_speak_analysis or we need raw tally)
        # We have internal `failure_tally` but it wasn't passed fully in data structure,
        # only `no_speak_analysis` text list.  
        # Let's rely on what we have. If `no_speak_analysis` has "Code (N)", parse it?
        # Or better, just fix `build_dashboard_data` to pass `failure_tally`.
        # For now, let's use `no_speak_analysis` lines.
        
        ns_ana = data.get("no_speak_analysis", [])
        for r in ns_ana:
            lines.append(f"- {r}")
            
        # Add flags
        for k, v in reasons.items():
            lines.append(f"- {k}: {v}Í±¥")
            
        if data.get("has_fact_driven_candidate"):
            lines.append("- **FACT Í∏∞Ï§ÄÏùÄ Ï∂©Ï°±ÌñàÏúºÎÇò Íµ¨Ï°∞ Ïã†Ìò∏ Î∂ÄÏ°±**")
            
        lines.append("")

    def _render_almost_candidates(self, cards: List[Dict], lines: List[str]):
        """Renders Top 3 candidates that were close (excluding READY)."""
        # Exclude READY
        candidates = [c for c in cards if c['status'] != 'READY']
        # cards are already sorted (HOLD then DROP, then Score).
        top_3 = candidates[:3]
        
        if not top_3: return

        lines.append("\n## ü•à TOP CANDIDATES (Almost)")
        lines.append("Îã§ÏùåÏùÄ ÏïÑÍπùÍ≤å ÏÑ†Ï†ïÎêòÏßÄ Î™ªÌïú ÏÉÅÏúÑ ÌõÑÎ≥¥ÏûÖÎãàÎã§.")
        lines.append("")
        
        for c in top_3:
            badge = "üü°" if c['status'] == 'HOLD' else "üî¥"
            status_text = "HOLD" if c['status'] == 'HOLD' else "DROP"
            
            # Normalized Reason
            reason = self._get_hold_reason(c) if c['status'] == 'HOLD' else c['reason']
            reason = reason.replace("ÏïÑÏßÅ ÎßêÌïòÏßÄ ÏïäÎäî Ïù¥Ïú†: ", "") # Simplify for bullet
            
            # Bridge
            bridge_mk = "üåâ Bridge Capable" if c.get('bridge_eligible') else ""
            
            lines.append(f"### {badge} {c['title']} ({status_text})")
            lines.append(f"- **Reason**: {reason}")
            if bridge_mk:
                 lines.append(f"- **Note**: {bridge_mk}")
            
            # Context stats
            ev_cnt = c.get('evidence_count', 0)
            lines.append(f"- **Evidence**: {ev_cnt} items")
            lines.append("")

    def _render_ready_card(self, c: Dict) -> str:
        """Renders the detailed READY card with Speak Pack."""
        lines = []
        is_fact = c.get('is_fact_driven')
        title_suffix = " (FACT-DRIVEN (Rule v1))" if is_fact else ""
        lines.append(f"\n### ‚úÖ {c['title']}{title_suffix}") 
        
        if is_fact and c.get('fact_why_now'):
            lines.append(f"> **WHY NOW**: {c['fact_why_now']}")
        
        # Tags Line
        tags = c.get('tags', [])
        if tags:
            lines.append(" ".join(tags))
            
        why = c.get('why_today')
        if why:
            lines.append(f"**Ïò§Îäò Ï∞çÎäî Ïù¥Ïú†**: {why}")
            
        lines.append(f"**ÌåêÎã® ÏöîÏïΩ**: ÏßÄÍ∏à ÏÑ§Î™Ö Í∞ÄÎä•Ìïú ÏµúÏÜå Ï°∞Í±¥ Ï∂©Ï°± (Ï¶ùÍ±∞ {c['evidence_count']}Í±¥)")
        
        sp = c.get('speak_pack')
        if sp:
            lines.append(f"\n**üéôÔ∏è SPEAK PACK**")
            lines.append(f"- **One-Liner**: {sp.get('one_liner')}")
            lines.append(f"- **Numbers**: {', '.join(sp.get('numbers', []))}")
            lines.append(f"- **Watch Next**: {', '.join(sp.get('watch_next', []))}")
            lines.append(f"- **Risk**: {sp.get('risk_note')}")
            
        refs = c.get('evidence_refs')
        if refs:
            lines.append(f"\n**üîç EVIDENCE REFERENCES**")
            for idx, r in enumerate(refs, 1):
                 src = r.get('source', {})
                 pub = src.get('publisher', 'unknown')
                 url = src.get('url', 'unknown')
                 lines.append(f"{idx}. {r['label']}: {r['value']} (Source: {pub} | URL: {url})")
        else:
            lines.append("\n**üîç EVIDENCE REFERENCES**")
            lines.append("- No verifiable evidence available.")
            
        lines.append("---")
        return "\n".join(lines)

    def _get_hold_reason(self, c: Dict) -> str:
        """Determines the single strongest human-readable reason for HOLD."""
        # 1. Sanity Flags (Highest Priority)
        flags = c.get('flags', [])
        if "TITLE_MISMATCH" in flags:
            return "ÏïÑÏßÅ ÎßêÌïòÏßÄ ÏïäÎäî Ïù¥Ïú†: Ï†úÎ™©Í≥º Í∑ºÍ±∞ Îç∞Ïù¥ÌÑ∞Ïùò Ïó∞Í¥ÄÏÑ±Ïù¥ ÎÇÆÏäµÎãàÎã§."
        if "PLACEHOLDER_EVIDENCE" in flags:
            return "ÏïÑÏßÅ ÎßêÌïòÏßÄ ÏïäÎäî Ïù¥Ïú†: Í∑ºÍ±∞ ÏàòÏπòÏóê ÌôïÏù∏ Î∂àÍ∞ÄÎä•Ìïú Í∞íÏù¥ Ìè¨Ìï®Îê®."
        if "EVIDENCE_TOO_THIN" in flags:
            return "ÏïÑÏßÅ ÎßêÌïòÏßÄ ÏïäÎäî Ïù¥Ïú†: ÎßêÌï† Ïàò ÏûàÎäî Í∑ºÍ±∞Í∞Ä ÎÑàÎ¨¥ Ï†ÅÏäµÎãàÎã§ (2Í∞ú ÎØ∏Îßå)."
            
        # 2. Quality Status Reason
        # Translate common engine codes to human sentence
        raw_reason = c.get('reason', '')
        if "Weak Evidence" in raw_reason or "Í∑ºÍ±∞ Îç∞Ïù¥ÌÑ∞Í∞Ä Î∂ÄÏ°±" in raw_reason:
            return "ÏïÑÏßÅ ÎßêÌïòÏßÄ ÏïäÎäî Ïù¥Ïú†: Ï£ºÏû•ÏùÑ Îí∑Î∞õÏπ®Ìï† Íµ¨Ï≤¥Ï†Å ÏàòÏπòÍ∞Ä Î∂ÄÏ°±Ìï©ÎãàÎã§."
        if "No Forward Signal" in raw_reason or "Ï∂îÌõÑ Í¥ÄÏ∞∞ ÏßÄÌëú" in raw_reason:
            return "ÏïÑÏßÅ ÎßêÌïòÏßÄ ÏïäÎäî Ïù¥Ïú†: Ïù¥ ÌòÑÏÉÅÏùò ÏßÄÏÜç Ïó¨Î∂ÄÎ•º ÌåêÎã®Ìï† ÏßÄÌëúÍ∞Ä ÏóÜÏäµÎãàÎã§."
            
        # 3. Fallback
        return f"ÏïÑÏßÅ ÎßêÌïòÏßÄ ÏïäÎäî Ïù¥Ïú†: {raw_reason}"

    def _get_reason_text(self, status: str, codes: List[str]) -> str:
        desc_map = self.reason_map.get("descriptions", {})
        st_map = desc_map.get(status, {})
        
        # If specific code match found in map
        for code in codes:
            for item in st_map.get("codes", []):
                if item["code"] == code:
                    return item["text"]
        
        return st_map.get("default", status)

    def _get_code_desc(self, status: str, code: str) -> str:
        desc_map = self.reason_map.get("descriptions", {})
        # Flatten all codes to find text
        for st in ["READY", "HOLD", "DROP"]:
            for item in desc_map.get(st, {}).get("codes", []):
                if item["code"] == code:
                    return item["text"]
        return code

    def _count_evidence_from_script(self, script_path: Path) -> int:
        if not script_path.exists(): return 0
        import re
        try:
            txt = script_path.read_text(encoding="utf-8")
            # Heuristic from ScriptQualityGate: count "- **" in evidence section
            # We just scan whole text for simplification or split logic?
            # Let's be reasonably accurate: Look for section "5)"
            parts = txt.split("### 5)")
            if len(parts) > 1:
                ev_part = parts[1].split("###")[0]
                return len(re.findall(r"-\s*\*\*", ev_part))
        except:
            pass
        return 0

    def _build_speak_pack(self, topic: Dict, evidence_cnt: int, flags: List[str]) -> Dict[str, Any]:
        """
        Builds a concise Speak Pack for human consumption.
        """
        title = topic.get("title", "Untitled")
        
        # 1. One-Liner
        # Template: "Ïôú ÏßÄÍ∏à: {reason} Ïã†Ìò∏Í∞Ä ÌôïÏù∏ÎêòÏñ¥ {title}Í∞Ä ÏÑ§Î™Ö Í∞ÄÎä•Ìïú ÏÉÅÌÉú."
        reasons = topic.get("key_reasons", [])
        main_reason = reasons[0] if reasons else "Ï£ºÏöî Îç∞Ïù¥ÌÑ∞ Î≥ÄÎèô"
        one_liner = f"Ïôú ÏßÄÍ∏à: {main_reason} Ïã†Ìò∏Í∞Ä ÌôïÏù∏ÎêòÏñ¥ '{title}'Í∞Ä ÏÑ§Î™Ö Í∞ÄÎä•Ìïú ÏÉÅÌÉú."
        
        # 2. Numbers
        nums = []
        raw_nums = topic.get("numbers", [])
        match_count = 0
        if raw_nums:
            for n in raw_nums[:3]:
                label = n.get("label", "Signal")
                val = n.get("value", "?")
                # Clean up value if needed, strict presentation
                nums.append(f"{label}: {val}")
                match_count += 1
        
        if match_count == 0:
            nums.append("(no numeric evidence)")
            
        # 3. Watch Next
        watch = []
        # Use risk or key reasons as proxy if no dedicated watchlist available in this topic view
        # Ideally we read 'watchlist' from script helper but topic json might not have it structured.
        # Minimal viable: Use Risk One + "Trend Confirmation"
        r1 = topic.get("risk_one")
        if r1: watch.append(f"{r1} Ïó¨Î∂Ä")
        watch.append("Í¥ÄÎ†® ÏßÄÌëú Ï∂îÏÑ∏ ÏßÄÏÜçÏÑ±")
        
        # 4. Risk Note
        if flags:
            risk_note = f"Risk: Îç∞Ïù¥ÌÑ∞ Í≤ÄÏ¶ù Ïã†Ìò∏({len(flags)}Í±¥) Ï°¥Ïû¨, Ï∂îÍ∞Ä ÌôïÏù∏ ÌïÑÏöî."
        else:
            risk_note = "Risk: Îã®Í∏∞ Î≥ÄÎèôÏÑ± ÌôïÎåÄ Íµ¨Í∞Ñ, Ï∂îÏÑ∏ ÌôïÏù∏ ÌïÑÏöî."
            
        return {
            "one_liner": one_liner,
            "numbers": nums,
            "watch_next": watch,
            "risk_note": risk_note
        }

    def _build_evidence_refs(self, topic: Dict, cand_map: Dict) -> List[Dict[str, Any]]:
        """
        Builds detailed evidence references using source candidates.
        """
        refs = []
        numbers = topic.get("numbers", [])
        source_cands = topic.get("source_candidates", [])
        
        for n in numbers[:5]:
            label = n.get("label", "Unknown")
            value = str(n.get("value", "Unknown"))
            
            # Find matching candidate
            matched_cand = None
            for cid in source_cands:
                cand = cand_map.get(cid)
                if not cand: continue
                # Linear search in cand numbers
                for c_num in cand.get("numbers", []):
                    if c_num.get("label") == label: # Heuristic match by label
                         matched_cand = cand
                         break
                if matched_cand: break
            
            # If no match found by label, maybe take the first source? 
            # Risk: might reference wrong source. Safe: explicit "unknown".
            # The constraints say "If source info is missing, explicitly set publisher='unknown'".
            
            publisher = "unknown"
            url = "unknown"
            context = "Extracted from topic numbers"
            
            if matched_cand:
                # Candidate usually has 'article' or 'event' metadata
                # Structure of candidate depends on 'topic_gate_candidates.json' schema
                # Usually: { ..., "article_meta": {"publisher": ...}, "url": ... } or "source_event": {...}
                # Let's support both common patterns in this system
                
                # Pattern 1: Event based
                if "source_event" in matched_cand:
                    evt = matched_cand["source_event"]
                    publisher = evt.get("publisher", "unknown")
                    url = evt.get("url", "unknown")
                    context = evt.get("title", context)
                # Pattern 2: Article/Raw based
                elif "article_meta" in matched_cand:
                     meta = matched_cand["article_meta"]
                     publisher = meta.get("publisher", "unknown")
                     url = matched_cand.get("url", "unknown")
                     context = matched_cand.get("title", context)
                # Fallback: Top level fields
                else:
                    publisher = matched_cand.get("publisher", publisher)
                    url = matched_cand.get("url", url)

            refs.append({
                "label": label,
                "value": value,
                "context": context,
                "source": {
                    "publisher": publisher,
                    "url": url
                }
            })
            
        return refs

    def _compute_flags(self, topic: Dict, evidence_cnt: int) -> List[str]:
        flags = []
        
        # 1. EVIDENCE_TOO_THIN
        if evidence_cnt < 2:
            flags.append("EVIDENCE_TOO_THIN")
            
        # 2. PLACEHOLDER_EVIDENCE
        # Check raw numbers if available
        nums = topic.get("numbers", [])
        for n in nums:
            val = str(n.get("value", "")).lower()
            if "need" in val or "defic" in val or val == "0" or val == "0.0":
                flags.append("PLACEHOLDER_EVIDENCE")
                break
                
        # 3. TITLE_MISMATCH (Simple Heuristic)
        # Check if title keywords appear in reason or evidence labels
        title = topic.get("title", "").lower()
        keywords = [k for k in title.split() if len(k) > 2] # Skip short words
        
        # Collect comparison text
        reasons = " ".join(topic.get("key_reasons", [])).lower()
        ev_labels = " ".join([n.get("label", "") for n in nums]).lower()
        context = reasons + " " + ev_labels
        
        # If significant part of title is missing in context
        # (This is very heuristic, let's just check if ANY keyword matches for now to be safe, 
        # or ALL? "mismatch" implies strong deviation. Let's say if NO keyword matches.)
        if keywords:
            match_found = False
            for k in keywords:
                if k in context:
                    match_found = True
                    break
            if not match_found:
                 flags.append("TITLE_MISMATCH")
                 
        return flags

    def _compute_recommender_tags(self, topic: Dict, flags: List[str]) -> List[str]:
        """Computes recommendation tags (Max 2)."""
        tags = []
        
        # 1. RISK-AWARE
        if flags:
            tags.append("‚ö†Ô∏è RISK-AWARE")
            
        # 2. STRUCTURAL SIGNAL
        # Use simple heuristic if 'matched_axes' not explicitly available in topic json (it's in bridge output)
        # But we can check if key_reasons mentions 'Structural'
        # Or heuristic: if total score > 80 (high confidence) -> might be structural
        # Better: use 'handoff_to_structural' field from Gate
        if topic.get("handoff_to_structural"):
            tags.append("üß† STRUCTURAL SIGNAL")
            
        # 3. TIME-SENSITIVE
        # Heuristic: if 'deadline' or 'D-Day' in title or risk
        # Or simple randomness for demo if no field? No, STRICT HEURISTIC.
        # Check risk_one for 'Short term'
        r1 = topic.get("risk_one", "").lower()
        if "short" in r1 or "imminent" in r1 or "today" in r1:
            tags.append("‚è≥ TIME-SENSITIVE")
            
        # 4. TRENDING NOW
        # If score is very high (top 10%)
        if topic.get("total_score", 0) > 85:
             tags.append("üî• TRENDING NOW")
             
        return tags[:2]

    def _compute_why_today(self, topic: Dict, speak_pack: Dict) -> str:
        """Generates the single line 'Why Today' hint."""
        # Use one-liner from speak pack but simplified
        if speak_pack:
             ol = speak_pack.get("one_liner", "")
             # Extract extraction: "Ïôú ÏßÄÍ∏à: X Ïã†Ìò∏Í∞Ä ÌôïÏù∏ÎêòÏñ¥..." -> "X Ïã†Ìò∏Í∞Ä ÌôïÏù∏ÎêòÏóàÏäµÎãàÎã§."
             # Or just use the reason directly
             return f"{ol.replace('Ïôú ÏßÄÍ∏à: ', '')}"
        return "ÏßÄÍ∏à ÏÑ§Î™Ö Í∞ÄÎä•Ìïú Ï°∞Í±¥ Ï∂©Ï°±"

    def _get_fact_why_now_hint(self, topic: Dict) -> str:
        """Generates template-based 'WHY NOW' hint for FACT-DRIVEN topics."""
        # Predefined Templates
        templates = {
            "FACT_GOV_PLAN": "Ï£ºÏöî Í∏∞Í¥Ä Î∞è Ï†ïÎ∂ÄÏùò Í≥µÏãù ÏßëÌñâ Í≥ÑÌöç Î∞úÌëú",
            "FACT_CORP_DISCLOSURE": "Í∏∞ÏóÖÏùò Í≥µÏãù Í≥µÏãú Î∞è Ïã§Ï†Å Îç∞Ïù¥ÌÑ∞ ÌôïÏù∏",
            "FACT_MACRO_DATA": "ÌïµÏã¨ Í±∞Ïãú ÏßÄÌëúÏùò ÏûÑÍ≥ÑÏπò ÎèåÌåå Î∞è ÏàòÏπòÌôî",
            "FACT_INVEST_FLOW": "ÎåÄÍ∑úÎ™® ÏûêÍ∏à ÌùêÎ¶Ñ Î∞è Ìà¨Ïûê ÏßëÌñâ Îç∞Ïù¥ÌÑ∞ Ìè¨Ï∞©",
            "MARKET_SIZE": "Ï£ºÏöî Î¶¨ÏÑúÏπò Í∏∞Í¥ÄÏù¥ ÏãúÏû• Í∑úÎ™®Î•º Ïû¨ÏÇ∞Ï†ï",
            "OPERATIONAL_START": "Ïã§Ï†ú Ïö¥ÏòÅ Í∞úÏãúÎ°ú Í≤ÄÏ¶ù Îã®Í≥Ñ ÏßÑÏûÖ",
            "REGULATORY_MILESTONE": "Í∑úÏ†ú ÌôòÍ≤Ω Î≥ÄÌôî Î∞è Î≤ïÏ†Å ÎßàÏùºÏä§ÌÜ§ Îã¨ÏÑ±"
        }
        
        # 1. Match by Tags
        tags = topic.get("tags", [])
        for tag in tags:
            if tag in templates:
                return templates[tag]
        
        # 2. Match by Category (metadata)
        category = topic.get("metadata", {}).get("fact_category")
        if category in templates:
            return templates[category]
            
        # 3. Match by Event Type
        event_type = topic.get("event_type", "").upper()
        if event_type in templates:
            return templates[event_type]
            
        return "(explanatory context insufficient)"

            
        return "(explanatory context insufficient)"

    def _check_fact_driven(self, topic: Dict) -> bool:
        """Checks if a topic matches FACT-DRIVEN rules via metadata or tags."""
        if topic.get("is_fact_driven") or topic.get("metadata", {}).get("is_fact_driven"):
            return True
        
        # Check tags for FACT_ prefix
        tags = topic.get("tags", [])
        if any(isinstance(tag, str) and tag.startswith("FACT_") for tag in tags):
            return True
            
        return False

    def save_snapshot(self, ymd: str, data: Dict[str, Any]) -> Path:
        """
        Saves the dashboard data to daily_lock.json for immutable reference.
        Path: data/topics/gate/{ymd}/daily_lock.json
        """
        gate_dir = self.base_dir / "data" / "topics" / "gate" / ymd.replace("-", "/")
        if not gate_dir.exists():
            gate_dir.mkdir(parents=True, exist_ok=True)
            
        lock_path = gate_dir / "daily_lock.json"
        lock_path.write_text(json.dumps(data, indent=2, ensure_ascii=False), encoding="utf-8")
        return lock_path
