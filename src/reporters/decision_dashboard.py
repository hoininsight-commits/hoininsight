import json
import os
from pathlib import Path
from typing import Dict, List, Any, Tuple, Optional
import yaml
from dataclasses import dataclass, asdict
from src.ops.post_mortem_tracker import PostMortemTracker
from src.ops.topic_memory import TopicMemory
from src.ops.narrative_saturation import NarrativeSaturation

@dataclass
class DecisionCard:
    """
    Final Output Card for Dashboard.
    Step 9: Speakable Candidate.
    Step 16: Portfolio Balance Metadata.
    Step 17: Time-to-Impact Metadata.
    Step 20: Topic Memory.
    Step 21: Narrative Saturation.
    """
    topic_id: str
    title: str
    status: str # READY, HOLD, DROP
    
    # Original Data Preservation
    reason: str = None
    evidence_count: int = 0
    raw_score: float = 0.0 # Was total_score in my previous edit? No, code uses raw_score
    
    # Core Data
    speak_pack: Optional[Dict[str, Any]] = None # Only for READY
    evidence_refs: List[Dict[str, str]] = None
    
    # Metadata
    tags: List[str] = None
    why_today: str = None
    flags: List[str] = None
    
    # Eligibility & Bridge
    bridge_eligible: bool = False
    is_fact_driven: bool = False
    fact_why_now: str = None
    eligibility_badge: str = None
    eligibility_reason: str = None
    
    # Narration Logic
    narration_level: int = 1
    narration_badge: str = None
    narration_helper: str = None
    narration_ceiling: str = None
    
    # Judgment & Rationale
    judgment_notes: List[str] = None
    selection_rationale: List[str] = None
    contrast_rationale: Dict[str, Any] = None
    impact_window: str = None
    impact_hint: str = None
    
    # Topic Memory
    memory_status: str = "NEW_TOPIC" # NEW_TOPIC, REVISIT, REGIME_UPDATE
    memory_meta: Dict[str, Any] = None
    
    # Narrative Saturation
    saturation_level: str = "NORMAL"
    saturation_count: int = 0
    saturation_axis: str = None
    
    # Re-Narration Permission (Step 22)
    renarration_status: str = None # PERMITTED, DISCOURAGED, or None (if NEW)
    renarration_reason: str = None
    
    # Post-Mortem
    outcome: str = None

class DecisionDashboard:
    """
    Reporter for the Topic Gate.
    Generates daily operational dashboard.
    """
    
    def __init__(self, base_dir: Path):
        self.base_dir = base_dir
        self.tracker = PostMortemTracker(base_dir)
        self.memory = TopicMemory(base_dir)
        self.saturation = NarrativeSaturation(base_dir)
        self.reason_map = self._load_reason_map()
        
    def _load_reason_map(self) -> Dict:
        path = self.base_dir / "registry/decision_reason_map_v1.yml"
        if not path.exists():
            return {}
        try:
            return yaml.safe_load(path.read_text(encoding="utf-8"))
        except:
            return {}

    def build_dashboard_data(self, ymd: str) -> Dict[str, Any]:
        """
        Aggregates data for the dashboard.
        """
        # 1. Load Gate Output
        gate_dir = self.base_dir / "data" / "topics" / "gate" / ymd.replace("-", "/")
        gate_out = gate_dir / "topic_gate_output.json"
        gate_cands = gate_dir / "topic_gate_candidates.json"
        
        # Load Candidates for Source Mapping
        cand_map = {}
        if gate_cands.exists():
            try:
                c_data = json.loads(gate_cands.read_text(encoding="utf-8"))
                for c in c_data.get("candidates", []):
                    cand_map[c.get("candidate_id")] = c
            except:
                pass

        # [Step 47.5] Load FACT-FIRST Shadow Pool
        fact_first_shadows = []
        topic_seeds = []
        narrative_hypotheses = []
        ff_path = self.base_dir / "data" / "topics" / "shadow_pool" / ymd.replace("-", "/") / "fact_first.json"
        if ff_path.exists():
            try:
                ff_data = json.loads(ff_path.read_text(encoding="utf-8"))
                fact_first_shadows = ff_data.get("topics", [])
                topic_seeds = ff_data.get("topic_seeds", [])
                narrative_hypotheses = ff_data.get("narrative_hypotheses", [])
            except Exception as e:
                print(f"[Dashboard] Error parsing fact_first shadows: {e}")

        # [Step 48] Load Fact Anchors
        fact_anchors = []
        fa_path = self.base_dir / "data" / "facts" / f"fact_anchors_{ymd.replace('-', '')}.json"
        if fa_path.exists():
            try:
                fa_data = json.loads(fa_path.read_text(encoding="utf-8"))
                fact_anchors = fa_data
            except Exception as e:
                print(f"[Dashboard] Error parsing fact anchors: {e}")

        topics = []
        if gate_out.exists():
            try:
                data = json.loads(gate_out.read_text(encoding="utf-8"))
                if isinstance(data, dict):
                    if "ranked" in data:
                        topics = data.get("ranked", [])
                    elif "top1" in data:
                        topics = [data["top1"]]
                    elif "topic_id" in data:
                        # Direct single topic object
                        topics = [data]
            except Exception as e:
                print(f"[Dashboard] Error parsing gate_out: {e}")
        
        # Post-Mortem History Loading (Step 18)
        from datetime import datetime, timedelta
        t_dt = datetime.strptime(ymd, "%Y-%m-%d")
        # Load [target_date + 1, target_date + 90]
        next_day_str = (t_dt + timedelta(days=1)).strftime("%Y-%m-%d")
        future_end_str = (t_dt + timedelta(days=90)).strftime("%Y-%m-%d")
        history = self.tracker.load_history(next_day_str, future_end_str)
        
        # Load Memory (Step 20) - 90 days lookback from today
        mem_index = self.memory.load_memory(ymd, lookback_days=90)
        
        # Load Saturation History (Step 21) - 14 days lookback
        sat_index = self.saturation.load_history(ymd, days=14)
        
        # Aggregate stats for today's panel (Past performance up to target_date)
        pm_stats = self.tracker.get_aggregate_stats(ymd, lookback_days=90)
        
        cards = []
        status_counts = {"READY": 0, "HOLD": 0, "DROP": 0}
        sat_summary = {"NORMAL": 0, "DENSE": 0, "SATURATED": 0}
        failure_tally = {}
        flag_tally = {}
        
        # 2. Process each topic
        for t in topics:
            tid = t.get("topic_id")
            if not tid: continue
            
            # Find script sidecar
            # Pattern: script_v1_{tid}.md.quality.json
            quality_file = gate_dir / f"script_v1_{tid}.md.quality.json"
            
            status = "DROP" # Default if no script
            codes = ["NO_SCRIPT"]
            evidence_cnt = 0
            
            if quality_file.exists():
                try:
                    q_data = json.loads(quality_file.read_text(encoding="utf-8"))
                    status = q_data.get("quality_status", "DROP")
                    codes = q_data.get("failure_codes", [])
                    # Infer evidence count from script if possible, or assume based on status
                    evidence_cnt = self._count_evidence_from_script(gate_dir / f"script_v1_{tid}.md")
                except:
                    pass
            
            # Translate Reason
            reason_text = self._get_reason_text(status, codes)
            
            # Tally
            status_counts[status] = status_counts.get(status, 0) + 1
            for c in codes:
                failure_tally[c] = failure_tally.get(c, 0) + 1
            
            # Compute Flags
            flags = self._compute_flags(t, evidence_cnt)
            for f in flags:
                flag_tally[f] = flag_tally.get(f, 0) + 1

            # Build Speak Pack & Recommender (only for READY)
            speak_pack = None
            evidence_refs = None
            tags = None
            why_today = None
            
            if status == "READY":
                speak_pack = self._build_speak_pack(t, evidence_cnt, flags)
                evidence_refs = self._build_evidence_refs(t, cand_map)
                # Recommender Hints
                tags = self._compute_recommender_tags(t, flags)
                why_today = self._compute_why_today(t, speak_pack)
                
                # Step 17: Time-to-Impact Tag
                impact_win, impact_hint = self._determine_impact_window(t, tags)
            else:
                impact_win = None
                impact_hint = None
                
            # Step 18: Post-Mortem Evaluation
            outcome = None
            # Step 20: Topic Memory
            mem_res = {"type": "NEW_TOPIC", "meta": None}
            # Step 21: Narrative Saturation
            sat_res = {"level": "NORMAL", "count": 0, "axis": None}
            
            if status == "READY":
                outcome = self.tracker.evaluate_topic(t, ymd, history)
                mem_res = self.memory.classify_topic(t, mem_index, current_date=ymd)
                sat_res = self.saturation.compute_saturation(t, sat_index)
                
                # Update Saturation Summary
                lvl = sat_res["level"]
                sat_summary[lvl] = sat_summary.get(lvl, 0) + 1
                
                # Step 22: Re-Narration Permission
                perm_status, perm_reason = self._determine_renarration_permission(
                    mem_res["type"], impact_win, outcome
                )
            else:
                 perm_status, perm_reason = None, None


            depth_info = self._calculate_narration_depth(t, status, self._check_fact_driven(t), t.get("handoff_to_structural", False))
            ceiling_reason = self._get_ceiling_reason(depth_info["narration_level"], self._check_fact_driven(t))
            
            cards.append(DecisionCard(
                topic_id=tid,
                title=t.get("title", "Untitled"),
                status=status,
                reason=reason_text,
                evidence_count=evidence_cnt,
                raw_score=t.get("total_score", 0.0),
                flags=flags,
                speak_pack=speak_pack,
                evidence_refs=evidence_refs,
                tags=tags,
                why_today=why_today,
                bridge_eligible=t.get("handoff_to_structural", False),
                is_fact_driven=self._check_fact_driven(t),
                fact_why_now=self._get_fact_why_now_hint(t) if self._check_fact_driven(t) else None,
                narration_ceiling=ceiling_reason,
                judgment_notes=self._build_judgment_notes({
                    **t, 
                    "status": status, 
                    "evidence_count": evidence_cnt,
                    "narration_level": depth_info["narration_level"],
                    "fact_why_now": self._get_fact_why_now_hint(t) if self._check_fact_driven(t) else None,
                    "is_fact_driven": self._check_fact_driven(t),
                    "flags": flags,
                    "narration_ceiling": ceiling_reason
                }),
                selection_rationale=self._build_selection_rationale({
                    **t,
                    "status": status,
                    "is_fact_driven": self._check_fact_driven(t),
                    "narration_level": depth_info["narration_level"],
                    "judgment_notes": self._build_judgment_notes({**t, "status": status, "evidence_count": evidence_cnt, "narration_level": depth_info["narration_level"], "fact_why_now": self._get_fact_why_now_hint(t) if self._check_fact_driven(t) else None, "is_fact_driven": self._check_fact_driven(t), "flags": flags, "narration_ceiling": ceiling_reason}),
                    "narration_ceiling": ceiling_reason
                }) if status == "READY" else None,
                impact_window=impact_win,
                impact_hint=impact_hint,
                outcome=outcome,
                memory_status=mem_res["type"],
                memory_meta=mem_res["meta"],
                saturation_level=sat_res["level"],
                saturation_count=sat_res["count"],
                saturation_axis=sat_res["axis"],
                renarration_status=perm_status,
                renarration_reason=perm_reason,
                **self._get_eligibility_info(status, self._check_fact_driven(t), flags, t.get("handoff_to_structural", False)),
                **depth_info
            ))
            
        # 3. Sort (Presentation Only)
        # Groups: READY -> HOLD -> DROP
        # Within: Score desc
        cards.sort(key=lambda x: (
            {"READY": 0, "HOLD": 1, "DROP": 2}.get(x.status, 3), 
            -x.raw_score
        ))
        
        # Step 15: Contrast Post-processing
        for c in cards:
            if c.status == "READY":
                c.contrast_rationale = self._get_contrast_rationale(c, [card for card in cards if card.status == "HOLD"])
        
        # 4. "Why No Speak" Analysis
        no_speak_reason = []
        if status_counts["READY"] == 0:
            # Top 3 blockers
            sorted_fails = sorted(failure_tally.items(), key=lambda x: x[1], reverse=True)[:3]
            for code, count in sorted_fails:
                 # Translate code
                 desc = self._get_code_desc(status="DROP", code=code) # Assume DROP context for blockers
                 no_speak_reason.append(f"{desc} ({count}Í±¥)")
        
        return {
            "summary": status_counts,
            "cards": [asdict(c) for c in cards],
            "no_speak_analysis": no_speak_reason,
            "flag_summary": flag_tally,
            "has_fact_driven_candidate": any(c.is_fact_driven for c in cards if c.status != 'READY'),
            "anomaly_driven_count": len([c for c in cards if not c.is_fact_driven]),
            "fact_driven_count": len([c for c in cards if c.is_fact_driven]),
            "total_topics": len(cards),
            "candidates_count": len([c for c in cards if c.status != 'DROP']),
            "judgment_summary": {
                "weak_timing": len([c for c in cards if c.judgment_notes and any("WHY NOW" in n for n in c.judgment_notes)]),
                "shallow_evidence": len([c for c in cards if c.judgment_notes and any("LEVEL 3" in n for n in c.judgment_notes)]),
                "narrative_risk": len([c for c in cards if c.judgment_notes and any("narrative risk" in n for n in c.judgment_notes)])
            },
            "shadow_pool": self._load_shadow_pool(),
            "post_mortem_summary": pm_stats,
            "auto_priority": self._generate_auto_priority(ymd, [asdict(c) for c in cards if c.status == 'READY'], self._load_shadow_pool()),
            "bundle_md": f"data/ops/bundles/{ymd.replace('-', '/')}/speak_bundle.md",
            "fact_first_shadows": fact_first_shadows,
            "fact_anchors": fact_anchors,
            "topic_seeds": topic_seeds,
            "narrative_hypotheses": narrative_hypotheses
        }

    def _render_fact_anchors_panel(self, lines: List[str], facts: List[Dict[str, Any]]):
        """Renders Step 48 Fact Anchors Panel."""
        if not facts:
            return
            
        lines.append("\n### üß± FACT ANCHORS COLLECTED TODAY")
        lines.append(f"- **Count**: {len(facts)}")
        
        # Breakdown
        types = {}
        for f in facts:
            t = f.get("fact_type", "OTHER")
            types[t] = types.get(t, 0) + 1
        breakdown = ", ".join([f"{k}: {v}" for k, v in types.items()])
        lines.append(f"- **Type Breakdown**: {breakdown}")
        
        # Sample (Top 3)
        lines.append("- **Samples (Top 3)**:")
        for f in facts[:3]:
            lines.append(f"  - [{f.get('fact_type')}] {f.get('fact_text')} ({f.get('source')})")
        lines.append("")

    def _render_structural_frames_panel(self, lines: List[str], shadows: List[Dict[str, Any]]):
        """Renders Step 49 Structural Frames Panel (Read-only)."""
        # Aggregate frames from shadows (FactFirstIngress output)
        frame_counts = {}
        samples = [] # List of (fact, frame_obj)
        
        for s in shadows:
            frames = s.get("structural_frames", [])
            for f in frames:
                f_name = f.get("frame", "UNKNOWN")
                frame_counts[f_name] = frame_counts.get(f_name, 0) + 1
                if len(samples) < 3:
                     samples.append((s.get("fact_anchor"), f))
                     
        if not frame_counts:
            return
            
        lines.append("\n### üß† STRUCTURAL FRAMES (FROM FACTS)")
        lines.append("> **Factual Context ‚Äî Not scored or approved**")
        lines.append("")
        
        # Breakdown
        breakdown = ", ".join([f"{k}: {v}" for k, v in frame_counts.items()])
        lines.append(f"- **Frame Counts Today**: {breakdown}")
        
        # Samples
        lines.append("- **Sample Mappings (Top 3)**:")
        for fact_text, frame_obj in samples:
            lines.append(f"  - `{fact_text}` ‚Üí **{frame_obj['frame']}**")
            lines.append(f"    - *{frame_obj['reason']}*")
        lines.append("")

    def _render_topic_seeds_panel(self, lines: List[str], seeds: List[Dict[str, Any]]):
        """Renders Step 50 Topic Seeds Panel (Read-only)."""
        if not seeds:
            return
            
        lines.append("\n### üå± TOPIC SEEDS (STRUCTURAL)")
        lines.append("> **Topic Seeds ‚Äî Pre-topics awaiting maturation**")
        lines.append("")
        lines.append("| Summary | Structural Frames | Facts | First Seen |")
        lines.append("|---|---|---|---|")
        
        for s in seeds:
            frames_str = ", ".join(s.get("structural_frames", []))
            fact_cnt = len(s.get("supporting_facts", []))
            lines.append(f"| {s.get('seed_summary')} | {frames_str} | {fact_cnt} | {s.get('first_seen')} |")
        lines.append("")

    def _render_narrative_hypotheses_panel(self, lines: List[str], hypos: List[Dict[str, Any]], seeds: List[Dict[str, Any]]):
        """Renders Step 51 Narrative Hypotheses Panel (Read-only)."""
        if not hypos:
            return
            
        seed_map = {s["seed_id"]: s for s in seeds}
        
        lines.append("\n### üß© NARRATIVE HYPOTHESES (PRE-SPEAK)")
        lines.append("> **Factual Narrative Hypotheses ‚Äî Neutral structural explanations**")
        lines.append("")
        lines.append("| Hypothesis | Linked Seed | Frames | Facts | Confidence |")
        lines.append("|---|---|---|---|---|")
        
        for h in hypos:
            seed = seed_map.get(h.get("seed_id"), {})
            frames_str = ", ".join(h.get("structural_frames", []))
            seed_sum = seed.get("seed_summary", "Unknown Seed")
            lines.append(f"| {h.get('hypothesis_text')} | {seed_sum} | {frames_str} | {h.get('supporting_fact_count')} | {h.get('confidence_level')} |")
        lines.append("")

    def _load_shadow_pool(self) -> Dict[str, Any]:
        """Loads Step 34 Shadow Candidate Pool."""
        p = self.base_dir / "data" / "ops" / "shadow_candidates.json"
        if p.exists():
            try:
                return json.loads(p.read_text(encoding="utf-8"))
            except:
                pass
        return {"count": 0, "candidates": []}

    def _render_post_mortem_panel(self, lines: List[str], stats: Dict[str, int]):
        """Renders Step 18 Aggregate Accountability Panel."""
        c = stats.get("CONFIRMED", 0)
        f = stats.get("FAILED", 0)
        u = stats.get("UNRESOLVED", 0)
        
        lines.append("### üß™ POST-MORTEM SUMMARY (Last 90 Days)")
        lines.append(f"- **CONFIRMED**: {c}")
        lines.append(f"- **FAILED**: {f}")
        lines.append(f"- **UNRESOLVED**: {u}")
        lines.append("")

    def _render_saturation_summary(self, lines: List[str], stats: Dict[str, int]):
        """Renders Step 21 Saturation Summary."""
        n = stats.get("NORMAL", 0)
        d = stats.get("DENSE", 0)
        s = stats.get("SATURATED", 0)
        
        lines.append("### üßØ NARRATIVE SATURATION SUMMARY (Last 14 Days)")
        lines.append(f"- **NORMAL (0-2)**: {n}")
        lines.append(f"- **DENSE (3-4)**: {d}")
        lines.append(f"- **SATURATED (5+)**: {s}")
        lines.append("")

    def render_markdown(self, data: Dict[str, Any], force_final_view: bool = False) -> str:
        # Step 23: Final Human View Toggle
        if force_final_view or os.environ.get("ENABLE_FINAL_VIEW") == "ON":
            return self._render_final_view(data)

        lines = []
        as_of_date = data.get("as_of_date", datetime.utcnow().strftime("%Y-%m-%d"))
        
        # Step 18: Aggregate Panel
        pm_stats = data.get("post_mortem_summary")
        if pm_stats:
             self._render_post_mortem_panel(lines, pm_stats)
             
        # Step 21: Saturation Panel
        sat_stats = data.get("saturation_summary")
        if sat_stats:
            self._render_saturation_summary(lines, sat_stats)

        # Step 44: Auto-Approval Panel (NEW)
        aa_path = self.base_dir / "data" / "ops" / "auto_approved_today.json"
        auto_approved_ids = []
        if aa_path.exists():
            try:
                aa_data = json.loads(aa_path.read_text(encoding="utf-8"))
                self._render_auto_approved_panel(lines, aa_data)
                auto_approved_ids = [a["topic_id"] for a in aa_data.get("auto_approved", [])]
            except:
                pass
        
        # Step 43: Auto-Priority Panel (NEW)
        ap_path = self.base_dir / "data" / "ops" / "auto_priority_today.json"
        if ap_path.exists():
            try:
                ap_data = json.loads(ap_path.read_text(encoding="utf-8"))
                self._render_auto_priority_panel(lines, ap_data)
            except:
                pass

        # Step 41: Correlation Panel (NEW)
        corr_path = self.base_dir / "data" / "ops" / "pick_outcome_30d.json"
        if corr_path.exists():
            try:
                corr_data = json.loads(corr_path.read_text(encoding="utf-8"))
                self._render_correlation_panel(lines, corr_data)
            except:
                pass

        cards = data.get("cards", [])
        
        # Partition Topics
        ready_topics = [c for c in cards if c['status'] == 'READY']
        hold_topics = [c for c in cards if c['status'] == 'HOLD']
        drop_topics = [c for c in cards if c['status'] == 'DROP']
        
        # Load Operator Decisions (Step 40)
        from src.ops.operator_decision_log import OperatorDecisionLog
        op_log = OperatorDecisionLog(self.base_dir)
        decisions_map = op_log.get_latest_decisions_map(as_of_date)
        
        lines.append("\n## DECISION DASHBOARD (Beta)\n")
        
        # Step 9: System Sanity & Drift Monitor
        self._render_sanity_panel(data, lines)
        self._render_drift_warnings(data, lines)
        
        # SCRIPT QUALITY Counters
        s = data.get("summary", {})
        lines.append(f"**SCRIPT QUALITY**: üü¢ READY={s.get('READY',0)} | üü° HOLD={s.get('HOLD',0)} | üî¥ DROP={s.get('DROP',0)}")

        # [Step 48] FACT ANCHORS COLLECTED TODAY
        self._render_fact_anchors_panel(lines, data.get("fact_anchors", []))

        # [Step 49] STRUCTURAL FRAMES (FROM FACTS)
        self._render_structural_frames_panel(lines, data.get("fact_first_shadows", []))

        # [Step 50] TOPIC SEEDS (STRUCTURAL)
        self._render_topic_seeds_panel(lines, data.get("topic_seeds", []))

        # [Step 51] NARRATIVE HYPOTHESES (PRE-SPEAK)
        self._render_narrative_hypotheses_panel(lines, data.get("narrative_hypotheses", []), data.get("topic_seeds", []))

        # [Step 47.5] FACT-FIRST SHADOW TOPICS
        ff_shadows = data.get("fact_first_shadows", [])
        if ff_shadows:
            lines.append("\n## üèπ FACT-FIRST SHADOW TOPICS")
            lines.append("> **Early Fact Capture ‚Äî Not anomaly-confirmed**")
            lines.append("")
            lines.append("| Fact Anchor | Structural Reason | Confidence |")
            lines.append("|---|---|---|")
            for ff in ff_shadows:
                lines.append(f"| {ff['fact_anchor']} | {ff['structural_reason']} | {ff['confidence']} |")
            lines.append("")
        
        # WHY NO SPEAK Panel (if needed)
        if not ready_topics:
            self._render_no_speak_panel(lines, data)
        
        # --- SECTION 1: TODAY - SPEAKABLE TOPICS ({len(ready_topics)}) ---
        if ready_topics:
            snapshot = self._build_portfolio_snapshot(cards)
            assessment = self._assess_portfolio_balance(snapshot)
            self._render_portfolio_balance(lines, snapshot, assessment)
            
        lines.append(f"\n## üé¨ TODAY ‚Äî SPEAKABLE TOPICS ({len(ready_topics)})")
        lines.append("‚Äª ÏãúÏä§ÌÖúÏùÄ ÏÑ†ÌÉùÌïòÏßÄ ÏïäÏäµÎãàÎã§. ÏïÑÎûòÎäî Ïò§Îäò ÏÑ§Î™Ö Í∞ÄÎä•Ìïú ÌõÑÎ≥¥ ÏöîÏïΩÏûÖÎãàÎã§.")
        
        if not ready_topics:
            lines.append("- (No topics ready for broadcast today)")
        else:
            # Split Lanes
            anomaly_lane = [c for c in ready_topics if not c.get('is_fact_driven')]
            fact_lane = [c for c in ready_topics if c.get('is_fact_driven')]
            
            # A) ANOMALY-DRIVEN (Signal First)
            lines.append(f"\n### üì° A) ANOMALY-DRIVEN (Signal First)")
            if not anomaly_lane:
                lines.append("_No ANOMALY-DRIVEN signals today_")
            else:
                for c in anomaly_lane[:5]: 
                    lines.append(self._render_ready_card(c, decisions_map, auto_approved_ids))
                if len(anomaly_lane) > 5:
                    lines.append("\n**Additional Anomaly Signals (Optional)**")
                    for c in anomaly_lane[5:]:
                        tags_str = " " + " ".join(c['tags']) if c.get('tags') else ""
                        lines.append(f"- {c['title']} (Evidence: {c['evidence_count']}){tags_str}")
            
            # B) FACT-DRIVEN (Fact First)
            lines.append(f"\n### üìë B) FACT-DRIVEN (Fact First)")
            if not fact_lane:
                lines.append("_No FACT-DRIVEN topics today_")
            else:
                for c in fact_lane[:5]:
                    lines.append(self._render_ready_card(c, decisions_map, auto_approved_ids))
                if len(fact_lane) > 5:
                    lines.append("\n**Additional Fact Topics (Optional)**")
                    for c in fact_lane[5:]:
                        tags_str = " " + " ".join(c['tags']) if c.get('tags') else ""
                        lines.append(f"- {c['title']} (Evidence: {c['evidence_count']}){tags_str}")
        
        # --- OPERATOR SUMMARY (Step 40) ---
        self._render_operator_summary(lines, decisions_map)

        # --- ALMOST CANDIDATES ---
        self._render_almost_candidates(cards, lines)
        
        # --- SHADOW CANDIDATES (Step 34) ---
        if len(ready_topics) < 3:
            shadow_data = data.get("shadow_pool", {"count": 0, "candidates": []})
            # Step 36, 37, 38, 39: Summary Panels
            self._render_shadow_aging_summary(lines, shadow_data.get("aging_summary", {}))
            self._render_readiness_summary(lines, shadow_data.get("readiness_summary", {}))
            self._render_signal_arrival_panel(lines, shadow_data.get("signal_arrival", {}), shadow_data.get("candidates", []))
            self._render_global_signal_watchlist(lines, shadow_data.get("global_watchlist", {}))
            self._render_shadow_candidates(lines, shadow_data, decisions_map)
        
        # --- SECTION 2: WATCHLIST - NOT YET (HOLD) ---
        lines.append(f"\n## üëÄ WATCHLIST ‚Äî NOT YET ({len(hold_topics)})")
        if not hold_topics:
            lines.append("- (No items on watchlist)")
        else:
            lines.append("| Status | Title | Why not speak yet? |")
            lines.append("|---|---|---|")
            for c in hold_topics:
                reason = self._get_hold_reason(c)
                lines.append(f"| ‚ö†Ô∏è HOLD | {c['title']} | {reason} |")
                
        # --- SECTION 3: ARCHIVE - DROP ---
        if drop_topics:
            lines.append(f"\n## üóëÔ∏è ARCHIVE ‚Äî DROP ({len(drop_topics)})")
            lines.append("<details><summary>Click to view dropped topics</summary>")
            lines.append("")
            lines.append("| Status | Title | Reason |")
            lines.append("|---|---|---|")
            for c in drop_topics:
                # Use simplified reason, remove internal codes if any leak
                r = c['reason'].replace("FAIL_HOOK", "Hook ÎØ∏Îã¨").replace("NO_EVIDENCE", "Ï¶ùÍ±∞ ÏóÜÏùå")
                lines.append(f"| ‚õî DROP | {c['title']} | {r} |")
            lines.append("</details>")

        return "\n".join(lines)

    def _render_no_speak_panel(self, lines: List[str], data: Dict[str, Any]):
        """Renders the detailed WHY NO SPEAK panel when READY=0."""
        # Aggregate failing reasons
        f_tally = data.get("flag_summary", {})
        # We also want specific failure codes from summary stats or detailed reasons
        # But aggregate is easier from the pre-calculated 'no_speak_analysis' if strictly codes.
        # However, prompt asks for "NO_EVIDENCE: N", "TITLE_MISMATCH: N" etc.
        # Let's combine flag_tally and top failure codes.
        
        lines.append("\n## üö´ WHY NO SPEAK (Today)")
        lines.append("> **Ïò§ÎäòÏùÄ ÏòÅÏÉÅÌôî Í∞ÄÎä•Ìïú ÌÜ†ÌîΩÏù¥ ÏóÜÏäµÎãàÎã§.** ÏïÑÎûò ÏÇ¨Ïú†Î°ú Ïù∏Ìï¥ Î≥¥Î•òÎêòÏóàÏäµÎãàÎã§.")
        lines.append("")
        
        # Merge lists
        reasons = {}
        # 1. From flags
        for f, cnt in f_tally.items():
            reasons[f] = cnt
            
        # 2. From failure codes (extracted from no_speak_analysis or we need raw tally)
        # We have internal `failure_tally` but it wasn't passed fully in data structure,
        # only `no_speak_analysis` text list.  
        # Let's rely on what we have. If `no_speak_analysis` has "Code (N)", parse it?
        # Or better, just fix `build_dashboard_data` to pass `failure_tally`.
        # For now, let's use `no_speak_analysis` lines.
        
        ns_ana = data.get("no_speak_analysis", [])
        for r in ns_ana:
            lines.append(f"- {r}")
            
        # Add flags
        for k, v in reasons.items():
            lines.append(f"- {k}: {v}Í±¥")
            
        if data.get("has_fact_driven_candidate"):
            lines.append("- **FACT Í∏∞Ï§ÄÏùÄ Ï∂©Ï°±ÌñàÏúºÎÇò Íµ¨Ï°∞ Ïã†Ìò∏ Î∂ÄÏ°±**")
            
        lines.append("")

    def _render_almost_candidates(self, cards: List[Dict], lines: List[str]):
        """Renders Top 3 candidates that were close (excluding READY)."""
        # Exclude READY
        candidates = [c for c in cards if c['status'] != 'READY']
        # cards are already sorted (HOLD then DROP, then Score).
        top_3 = candidates[:3]
        
        if not top_3: return

        lines.append("\n## ü•à TOP CANDIDATES (Almost)")
        lines.append("Îã§ÏùåÏùÄ ÏïÑÍπùÍ≤å ÏÑ†Ï†ïÎêòÏßÄ Î™ªÌïú ÏÉÅÏúÑ ÌõÑÎ≥¥ÏûÖÎãàÎã§.")
        lines.append("")
        
        for c in top_3:
            status_icon = "üü°" if c['status'] == 'HOLD' else "üî¥"
            status_text = "HOLD" if c['status'] == 'HOLD' else "DROP"
            
            # Eligibility Badge
            elig_badge = c.get('eligibility_badge', '‚è∏Ô∏è NOT SPEAKABLE')
            eligibility_reason = c.get('eligibility_reason', 'Criteria not met')
            
            # Narration Depth Badge
            n_badge = c.get('narration_badge', 'üé§ LEVEL 1')
            n_helper = c.get('narration_helper', 'Macro explanation only')
            ceiling = c.get('narration_ceiling')
            
            # Normalized Reason
            reason = self._get_hold_reason(c) if c['status'] == 'HOLD' else c['reason']
            reason = reason.replace("ÏïÑÏßÅ ÎßêÌïòÏßÄ ÏïäÎäî Ïù¥Ïú†: ", "") # Simplify for bullet
            
            # Bridge
            bridge_mk = "üåâ Bridge Capable" if c.get('bridge_eligible') else ""
            
            lines.append(f"### {status_icon} {c['title']} ({status_text})")
            lines.append(f"**{elig_badge}**: {eligibility_reason}")
            lines.append(f"**{n_badge}**: {n_helper}")
            if ceiling:
                lines.append(f"**Ceiling**: {ceiling}")
            
            # Step 8: Promotion Requirements
            self._render_promotion_requirements(c.get('narration_level', 1), c.get('is_fact_driven', False), lines)
            
            lines.append(f"- **Reason**: {reason}")
            if bridge_mk:
                 lines.append(f"- **Note**: {bridge_mk}")
            
            # Context stats
            ev_cnt = c.get('evidence_count', 0)
            lines.append(f"- **Evidence**: {ev_cnt} items")
            
            # Judgment Notes
            notes = c.get('judgment_notes')
            if notes:
                lines.append(f"\n‚ö†Ô∏è **JUDGMENT NOTES**")
                for n in notes:
                    lines.append(f"- {n}")
            lines.append("")

    def _render_shadow_candidates(self, lines: List[str], shadow_data: Dict[str, Any], decisions_map: Dict[str, Dict]):
        """Renders Step 34 Shadow Candidates Pool (Grey tone, non-actionable)."""
        lines.append("\n### üîò SHADOW CANDIDATES (Preparation Pool)")
        lines.append("> **NOT FOR NARRATION YET** ‚Äî Structurally promising topics awaiting additional triggers.")
        
        candidates = shadow_data.get("candidates", [])
        if not candidates:
            lines.append("_Shadow pool empty ‚Äî no promotable topics detected._")
            return

        for c in candidates:
            tid = c.get("topic_id")
            # Grey tone style using blockquote or simple text
            lines.append(f"#### ‚óΩ {c['title']} {self._get_operator_badge(tid, decisions_map)} (Impact: {c['impact_window']})")
            
            # Step 40: SHADOW Action Bar
            self._render_shadow_action_bar(lines, tid, c['title'])
            
            lines.append(f"- **Lane**: {c['lane']}")
            lines.append(f"- **Why not speak**: {c['why_not_speak']}")
            
            # Step 35: Trigger Map Rendering
            tm = c.get("trigger_map", {})
            if tm:
                lines.append("\n    > **PROMOTION READINESS (Still NOT for narration)**")
                missing = ", ".join(tm.get("missing_triggers", []))
                sources = ", ".join(tm.get("source_hint", []))
                lines.append(f"    - **Missing**: {missing}")
                lines.append(f"    - **Expected From**: {sources}")
                lines.append(f"    - **Recheck**: {tm.get('earliest_recheck', 'AFTER_7D')}")
            
            # Step 36: Shadow Age Rendering
            aging = c.get("aging", {})
            if aging:
                state = aging.get("aging_state")
                days = aging.get("days_in_shadow", 0)
                state_icon = ""
                if state == "STALE": state_icon = " ‚ö†Ô∏è"
                elif state == "DECAYING": state_icon = " ‚ö†Ô∏è [Consider drop]"
                elif state == "EXPIRED": state_icon = " üßä [Likely obsolete]"
                lines.append(f"    - **Shadow Age**: {state}{state_icon} ({days} days)")
            
            # Step 38: Signal Status Rendering
            s_status = c.get("signal_status", {})
            matched = s_status.get("matched_signals", [])
            unmatched = s_status.get("unmatched_signals", [])
            
            if matched or unmatched:
                lines.append("\n    > **SIGNAL STATUS**")
                for s in matched:
                    lines.append(f"    - ‚úÖ Arrived: {s}")
                for s in unmatched:
                    lines.append(f"    - ‚è≥ Still waiting: {s}")
            
            # Step 39: Promotion Readiness Rendering
            rd = c.get("readiness", {})
            if rd:
                bucket = rd.get("readiness_bucket")
                matched = rd.get("matched_count", 0)
                required = rd.get("required_count", 0)
                
                bucket_icon = "‚ö™"
                if bucket == "READY_TO_PROMOTE": bucket_icon = "‚úÖ"
                elif bucket == "NEARLY_READY": bucket_icon = "üü°"
                elif bucket == "FAR": bucket_icon = "üí§"
                
                lines.append(f"\n    > **PROMOTION READINESS**")
                lines.append(f"    - **Bucket**: {bucket_icon} {bucket}")
                lines.append(f"    - **Progress**: {matched} / {required} signals")
                
                missing = rd.get("missing_signals", [])
                if missing:
                    lines.append(f"    - **Missing**: {', '.join(missing)}")
                
                hint = rd.get("operator_hint")
                if hint:
                    lines.append(f"    - *{hint}*")
            lines.append("")

    def _render_readiness_summary(self, lines: List[str], summary: Dict[str, int]):
        """Renders Step 39 Promotion Readiness Summary Panel."""
        if not summary or not any(summary.values()): return
        lines.append("\n#### üìä PROMOTION READINESS SUMMARY")
        lines.append(f"- **READY_TO_PROMOTE**: {summary.get('READY_TO_PROMOTE', 0)} ‚úÖ")
        lines.append(f"- **NEARLY_READY**: {summary.get('NEARLY_READY', 0)} üü°")
        lines.append(f"- **IN_PROGRESS**: {summary.get('IN_PROGRESS', 0)} ‚ö™")
        lines.append(f"- **FAR**: {summary.get('FAR', 0)} üí§")

    def _render_signal_arrival_panel(self, lines: List[str], arrival_data: Dict[str, Any], candidates: List[Dict]):
        """Renders Step 38 Global Signal Arrival Panel."""
        arrived = arrival_data.get("arrived_signals", [])
        lines.append("\n#### üì® SIGNAL ARRIVAL TODAY")
        
        if not arrived:
            lines.append("- _No monitored signals arrived today._")
            return
            
        for s in arrived:
            # Count how many shadows matched
            match_cnt = sum(1 for c in candidates if s in c.get("signal_status", {}).get("matched_signals", []))
            lines.append(f"- **{s}**: Arrived ({match_cnt} shadows matched)")

    def _render_global_signal_watchlist(self, lines: List[str], g_watchlist: Dict[str, int]):
        """Renders Step 37 Global Signal Watchlist Panel."""
        if not g_watchlist or not any(g_watchlist.values()): return
        lines.append("\n#### üî≠ GLOBAL SIGNAL WATCHLIST (Waiting For)")
        for signal, count in g_watchlist.items():
            if count > 0:
                lines.append(f"- **{signal}**: {count} topics")

    def _render_shadow_aging_summary(self, lines: List[str], summary: Dict[str, int]):
        """Renders Step 36 Shadow Aging Summary Panel."""
        if not any(summary.values()): return
        lines.append("\n#### üßä SHADOW AGING SUMMARY")
        lines.append(f"- **FRESH**: {summary.get('FRESH', 0)}")
        lines.append(f"- **STALE**: {summary.get('STALE', 0)} ‚ö†Ô∏è")
        lines.append(f"- **DECAYING**: {summary.get('DECAYING', 0)} ‚ö†Ô∏è")
        lines.append(f"- **EXPIRED**: {summary.get('EXPIRED', 0)} üßä")

    def _determine_renarration_permission(self, memory_status: str, impact_window: str, outcome: str) -> Tuple[Optional[str], Optional[str]]:
        """
        Step 22: Determines if re-narration is PERMITTED or DISCOURAGED.
        Only applies if topic is NOT NEW.
        """
        if memory_status == "NEW_TOPIC":
            return None, None
            
        # Rules for PERMITTED
        if memory_status == "REGIME_UPDATE":
            return "PERMITTED", "Íµ≠Î©¥ Î≥ÄÌôîÍ∞Ä Í∞êÏßÄÎêòÏñ¥ Ïû¨ÏÑ§Î™Ö Í∞ÄÎä•"
            
        if impact_window in ["IMMEDIATE", "NEAR"]:
            return "PERMITTED", "ÏãúÍ∏âÌïú ÏòÅÌñ•Î†•ÏúºÎ°ú Ïù∏Ìï¥ Ïû¨ÏÑ§Î™Ö ÌïÑÏöî"
            
        if outcome == "FAILED":
            return "PERMITTED", "Ïù¥Ï†Ñ ÏòàÏ∏° Ïã§Ìå®Î°ú Ïù∏Ìïú ÏÇ¨ÌõÑ Î∂ÑÏÑù ÌïÑÏöî"
            
        # Default DISCOURAGED
        return "DISCOURAGED", "ÏµúÍ∑º Î∞òÎ≥µ ÏÜåÎπÑÎêú ÏÑúÏÇ¨Î°ú Ïã†Í∑ú Ï†ïÎ≥¥ ÏóÜÏùå"

    def _render_ready_card(self, c: Dict, decisions_map: Dict[str, Dict], auto_approved_ids: List[str] = None) -> str:
        """Renders the detailed READY card with Speak Pack."""
        tid = c.get('topic_id')
        lines = []
        is_fact = c.get('is_fact_driven')
        title_suffix = " (FACT-DRIVEN (Rule v1))" if is_fact else ""
        
        is_auto = auto_approved_ids and tid in auto_approved_ids
        aa_badge = " | ü§ñ **AUTO-APPROVED** üîí" if is_auto else ""
        
        lines.append(f"\n### ‚úÖ {c['title']}{title_suffix} {self._get_operator_badge(tid, decisions_map)}{aa_badge}") 
        
        # Step 40: READY Action Bar
        self._render_ready_action_bar(lines, tid, c['title'])
        
        # Step 14: Selection Rationale
        rationale = c.get('selection_rationale')
        if rationale:
            lines.append(f"\nüß≠ **SELECTION RATIONALE**")
            for r in rationale:
                lines.append(f"- {r}")
                
        # Step 20: Topic Memory Badge (Prospective)
        mem = c.get('memory_status', "NEW_TOPIC")
        meta = c.get('memory_meta')
        if mem == "REVISIT":
            last_date = meta.get('last_date', 'Unknown')
            lines.append(f"\nüß† **TOPIC MEMORY**: REVISIT (Last: {last_date})")
            lines.append("> ‚ö†Ô∏è **NOTE**: Ïù¥ ÌÜ†ÌîΩÏùÄ Ïù¥ÎØ∏ Îã§Î§ÑÏßÑ Î∞î ÏûàÏùå ‚Äî Î∞òÎ≥µ ÎÇ¥Î†àÏù¥ÏÖò Ï£ºÏùò")
        elif mem == "REGIME_UPDATE":
            last_date = meta.get('last_date', 'Unknown')
            lines.append(f"\nüß† **TOPIC MEMORY**: REGIME UPDATE (Last: {last_date})")
        # NEW_TOPIC is implicit/hidden or explicit? 
        # Requirement: "Brain TOPIC MEMORY: NEW / REVISIT / REGIME UPDATE"
        # "Render badge... On READY topic cards only"
        # So we render for NEW too? "NEW"
        elif mem == "NEW_TOPIC":
             lines.append(f"\nüß† **TOPIC MEMORY**: NEW")

        # Step 21: Narrative Saturation Badge (Prospective)
        sat_lvl = c.get('saturation_level', 'NORMAL')
        sat_cnt = c.get('saturation_count', 0)
        if sat_lvl != "NORMAL": # Display only if significant? Or always?
            # "Render Saturation Warning... For READY topics only"
            # "NARRATIVE SATURATION: NORMAL / DENSE / SATURATED"
            # Let's show always for visibility?
            pass
            
        lines.append(f"\nüßØ **NARRATIVE SATURATION**: {sat_lvl} ({sat_cnt} recent)")
        if sat_lvl == "SATURATED":
            lines.append("> üßØ **WARNING**: Ïù¥ÎØ∏ ÏãúÏû•ÏóêÏÑú Ï∂©Î∂ÑÌûà ÏÜåÎπÑÎêú ÏÑúÏÇ¨ ‚Äî Î∞òÎ≥µ Ï£ºÏùò")

        # Step 22: Re-Narration Permission Block
        ren_status = c.get('renarration_status')
        if ren_status:
            lines.append(f"\nüîÅ **RE-NARRATION**")
            lines.append(f"- **Status**: {ren_status}")
            lines.append(f"- **Reason**: {c.get('renarration_reason')}")
            
        # Step 15: Contrast Rationale
        contrast = c.get('contrast_rationale')
        if contrast:
            lines.append(f"\n‚öñÔ∏è **CONTRAST (Why this over others)**")
            lines.append(f"- Selected: {contrast.get('selected_reason')}")
            rejections = contrast.get('rejections', [])
            for rj in rejections:
                lines.append(f"- Rejected: {rj['topic_id']} ‚Äî {rj['reason']}")
                
        if is_fact and c.get('fact_why_now'):
            lines.append(f"> **WHY NOW**: {c['fact_why_now']}")
            
        # Step 17: Impact Window
        imp_win = c.get('impact_window')
        if imp_win:
            imp_hint = c.get('impact_hint', '')
            lines.append(f"\n**‚è± IMPACT WINDOW**: {imp_win}")
            lines.append(f"> {imp_hint}")
            
        badge = c.get('eligibility_badge', '‚è∏Ô∏è NOT SPEAKABLE')
        reason = c.get('eligibility_reason', 'Criteria not met')
        lines.append(f"\n**{badge}**: {reason}")
        
        # Narration Depth Badge
        n_badge = c.get('narration_badge', 'üé§ LEVEL 1')
        n_helper = c.get('narration_helper', 'Macro explanation only')
        lines.append(f"**{n_badge}**: {n_helper}")
        
        ceiling = c.get('narration_ceiling')
        if ceiling:
            lines.append(f"**Ceiling**: {ceiling}")
        
        # Step 8: Promotion Requirements
        self._render_promotion_requirements(c.get('narration_level', 1), c.get('is_fact_driven', False), lines)
        
        # Tags Line
        tags = c.get('tags', [])
        if tags:
            lines.append(" ".join(tags))
            
        why = c.get('why_today')
        if why:
            lines.append(f"**Ïò§Îäò Ï∞çÎäî Ïù¥Ïú†**: {why}")
            
        lines.append(f"**ÌåêÎã® ÏöîÏïΩ**: ÏßÄÍ∏à ÏÑ§Î™Ö Í∞ÄÎä•Ìïú ÏµúÏÜå Ï°∞Í±¥ Ï∂©Ï°± (Ï¶ùÍ±∞ {c['evidence_count']}Í±¥)")
        
        # Judgment Notes
        notes = c.get('judgment_notes')
        if notes:
            lines.append(f"\n‚ö†Ô∏è **JUDGMENT NOTES**")
            for n in notes:
                lines.append(f"- {n}")
        
        sp = c.get('speak_pack')
        if sp:
            lines.append(f"\n**üéôÔ∏è SPEAK PACK**")
            lines.append(f"- **One-Liner**: {sp.get('one_liner')}")
            lines.append(f"- **Numbers**: {', '.join(sp.get('numbers', []))}")
            lines.append(f"- **Watch Next**: {', '.join(sp.get('watch_next', []))}")
            lines.append(f"- **Risk**: {sp.get('risk_note')}")
            
        refs = c.get('evidence_refs')
        if refs:
            lines.append(f"\n**üîç EVIDENCE REFERENCES**")
            for idx, r in enumerate(refs, 1):
                 src = r.get('source', {})
                 pub = src.get('publisher', 'unknown')
                 url = src.get('url', 'unknown')
                 lines.append(f"{idx}. {r['label']}: {r['value']} (Source: {pub} | URL: {url})")
        else:
            lines.append("\n**üîç EVIDENCE REFERENCES**")
            lines.append("- No verifiable evidence available.")
            
        # Step 19: Accountability View (Separated)
        outcome = c.get('outcome')
        if outcome:
            lines.append(f"\n--- üõ°Ô∏è ACCOUNTABILITY CHECK ---")
            if outcome != "UNRESOLVED":
                lines.append(f"**üß™ OUTCOME**: {outcome}")
            else:
                lines.append(f"_üß™ OUTCOME: {outcome}_")
            
        lines.append("---")
        return "\n".join(lines)

    def _render_final_view(self, data: Dict[str, Any]) -> str:
        """Step 23: Final Human View - Decision Focused."""
        cards = data.get("cards", [])
        sorted_cards = self._sort_for_final_view(cards)
        
        lines = []
        # Header
        # Assume today's date from first card? or data? 
        # But data doesn't have top level date. 
        # We'll use generic header or try to extract.
        lines.append("# üéôÔ∏è DAILY EDITORIAL DECISION (FINAL VIEW)")
        lines.append("\n_System diagnostics hidden. Showing prioritized decision metrics only._\n")
        
        # Top 5
        top_5 = sorted_cards[:5]
        rest = sorted_cards[5:]
        
        for c in top_5:
            lines.append(self._render_final_card(c))
            
        if rest:
            lines.append("\n### üëá More Candidates")
            lines.append(f"<details><summary>Show {len(rest)} more...</summary>\n")
            for c in rest:
                lines.append(self._render_final_card(c))
            lines.append("\n</details>")
            
        return "\n".join(lines)

    def _sort_for_final_view(self, cards: List[Dict]) -> List[Dict]:
        """
        Sorts for editorial priority:
        1. Speakable + (Permitted | NULL)
        2. Speakable + Discouraged
        3. Not Speakable
        
        Secondary: Level (Desc), Impact (Asc)
        """
        def sort_key(c):
             # Group Logic
             status = c.get('status', 'DROP')
             perm = c.get('renarration_status') 
             
             # Group 1: READY + (Permitted or None(New))
             # Group 2: READY + Discouraged
             # Group 3: Not READY
             
             if status == "READY":
                 if perm == "DISCOURAGED":
                     group = 2
                 else:
                     group = 1
             else:
                 group = 3
                 
             # Level (Desc) -> use negative
             level = -c.get('narration_level', 0)
             
             # Impact (Asc) -> IMMEDIATE(0) < NEAR(1) < MID(2) < LONG(3)
             imp_map = {"IMMEDIATE": 0, "NEAR": 1, "MID": 2, "LONG": 3}
             impact = imp_map.get(c.get('impact_window', 'LONG'), 4)
             
             return (group, level, impact)
             
        return sorted(cards, key=sort_key)

    def _render_final_card(self, c: Dict) -> str:
        """Minimalist card for Final View."""
        lines = []
        is_ready = c.get('status') == "READY"
        icon = "‚úÖ" if is_ready else "‚è∏Ô∏è"
        
        title = c.get('title')
        lines.append(f"### {icon} {title}")
        
        # Badges Row
        badges = []
        if is_ready:
            badges.append("üéôÔ∏è SPEAKABLE")
            badges.append(c.get('narration_badge', 'üé§ L1'))
            perm = c.get('renarration_status')
            if perm:
                badges.append(f"üîÅ {perm}")
        else:
            badges.append(c.get('eligibility_badge', 'NOT SPEAKABLE'))
            
        lines.append(" | ".join(badges))
        
        # Content
        if c.get('why_today'):
            lines.append(f"> **WHY**: {c['why_today']}")
            
        # Rationale (First point only)
        rats = c.get('selection_rationale')
        if rats and len(rats) > 0:
            lines.append(f"- üß≠ {rats[0]} (and {len(rats)-1} more..)" if len(rats)>1 else f"- üß≠ {rats[0]}")
            
        # Speak Pack (Collapsed)
        sp = c.get('speak_pack')
        if sp:
            lines.append("<details><summary>üéôÔ∏è Speak Pack (Script)</summary>")
            lines.append(f"- One-Liner: {sp.get('one_liner')}")
            lines.append(f"- Risk: {sp.get('risk_note')}")
            lines.append("</details>")
            
        lines.append("\n---")
        return "\n".join(lines)

    def _get_hold_reason(self, c: Dict) -> str:
        """Determines the single strongest human-readable reason for HOLD."""
        # 1. Sanity Flags (Highest Priority)
        flags = c.get('flags', [])
        if "TITLE_MISMATCH" in flags:
            return "ÏïÑÏßÅ ÎßêÌïòÏßÄ ÏïäÎäî Ïù¥Ïú†: Ï†úÎ™©Í≥º Í∑ºÍ±∞ Îç∞Ïù¥ÌÑ∞Ïùò Ïó∞Í¥ÄÏÑ±Ïù¥ ÎÇÆÏäµÎãàÎã§."
        if "PLACEHOLDER_EVIDENCE" in flags:
            return "ÏïÑÏßÅ ÎßêÌïòÏßÄ ÏïäÎäî Ïù¥Ïú†: Í∑ºÍ±∞ ÏàòÏπòÏóê ÌôïÏù∏ Î∂àÍ∞ÄÎä•Ìïú Í∞íÏù¥ Ìè¨Ìï®Îê®."
        if "EVIDENCE_TOO_THIN" in flags:
            return "ÏïÑÏßÅ ÎßêÌïòÏßÄ ÏïäÎäî Ïù¥Ïú†: ÎßêÌï† Ïàò ÏûàÎäî Í∑ºÍ±∞Í∞Ä ÎÑàÎ¨¥ Ï†ÅÏäµÎãàÎã§ (2Í∞ú ÎØ∏Îßå)."
            
        # 2. Quality Status Reason
        # Translate common engine codes to human sentence
        raw_reason = c.get('reason', '')
        if "Weak Evidence" in raw_reason or "Í∑ºÍ±∞ Îç∞Ïù¥ÌÑ∞Í∞Ä Î∂ÄÏ°±" in raw_reason:
            return "ÏïÑÏßÅ ÎßêÌïòÏßÄ ÏïäÎäî Ïù¥Ïú†: Ï£ºÏû•ÏùÑ Îí∑Î∞õÏπ®Ìï† Íµ¨Ï≤¥Ï†Å ÏàòÏπòÍ∞Ä Î∂ÄÏ°±Ìï©ÎãàÎã§."
        if "No Forward Signal" in raw_reason or "Ï∂îÌõÑ Í¥ÄÏ∞∞ ÏßÄÌëú" in raw_reason:
            return "ÏïÑÏßÅ ÎßêÌïòÏßÄ ÏïäÎäî Ïù¥Ïú†: Ïù¥ ÌòÑÏÉÅÏùò ÏßÄÏÜç Ïó¨Î∂ÄÎ•º ÌåêÎã®Ìï† ÏßÄÌëúÍ∞Ä ÏóÜÏäµÎãàÎã§."
            
        # 3. Fallback
        return f"ÏïÑÏßÅ ÎßêÌïòÏßÄ ÏïäÎäî Ïù¥Ïú†: {raw_reason}"

    def _get_reason_text(self, status: str, codes: List[str]) -> str:
        desc_map = self.reason_map.get("descriptions", {})
        st_map = desc_map.get(status, {})
        
        # If specific code match found in map
        for code in codes:
            for item in st_map.get("codes", []):
                if item["code"] == code:
                    return item["text"]
        
        return st_map.get("default", status)

    def _get_code_desc(self, status: str, code: str) -> str:
        desc_map = self.reason_map.get("descriptions", {})
        # Flatten all codes to find text
        for st in ["READY", "HOLD", "DROP"]:
            for item in desc_map.get(st, {}).get("codes", []):
                if item["code"] == code:
                    return item["text"]
        return code

    def _count_evidence_from_script(self, script_path: Path) -> int:
        if not script_path.exists(): return 0
        import re
        try:
            txt = script_path.read_text(encoding="utf-8")
            # Heuristic from ScriptQualityGate: count "- **" in evidence section
            # We just scan whole text for simplification or split logic?
            # Let's be reasonably accurate: Look for section "5)"
            parts = txt.split("### 5)")
            if len(parts) > 1:
                ev_part = parts[1].split("###")[0]
                return len(re.findall(r"-\s*\*\*", ev_part))
        except:
            pass
        return 0

    def _build_speak_pack(self, topic: Dict, evidence_cnt: int, flags: List[str]) -> Dict[str, Any]:
        """
        Builds a concise Speak Pack for human consumption.
        """
        title = topic.get("title", "Untitled")
        
        # 1. One-Liner
        # Template: "Ïôú ÏßÄÍ∏à: {reason} Ïã†Ìò∏Í∞Ä ÌôïÏù∏ÎêòÏñ¥ {title}Í∞Ä ÏÑ§Î™Ö Í∞ÄÎä•Ìïú ÏÉÅÌÉú."
        reasons = topic.get("key_reasons", [])
        main_reason = reasons[0] if reasons else "Ï£ºÏöî Îç∞Ïù¥ÌÑ∞ Î≥ÄÎèô"
        one_liner = f"Ïôú ÏßÄÍ∏à: {main_reason} Ïã†Ìò∏Í∞Ä ÌôïÏù∏ÎêòÏñ¥ '{title}'Í∞Ä ÏÑ§Î™Ö Í∞ÄÎä•Ìïú ÏÉÅÌÉú."
        
        # 2. Numbers
        nums = []
        raw_nums = topic.get("numbers", [])
        match_count = 0
        if raw_nums:
            for n in raw_nums[:3]:
                label = n.get("label", "Signal")
                val = n.get("value", "?")
                # Clean up value if needed, strict presentation
                nums.append(f"{label}: {val}")
                match_count += 1
        
        if match_count == 0:
            nums.append("(no numeric evidence)")
            
        # 3. Watch Next
        watch = []
        # Use risk or key reasons as proxy if no dedicated watchlist available in this topic view
        # Ideally we read 'watchlist' from script helper but topic json might not have it structured.
        # Minimal viable: Use Risk One + "Trend Confirmation"
        r1 = topic.get("risk_one")
        if r1: watch.append(f"{r1} Ïó¨Î∂Ä")
        watch.append("Í¥ÄÎ†® ÏßÄÌëú Ï∂îÏÑ∏ ÏßÄÏÜçÏÑ±")
        
        # 4. Risk Note
        if flags:
            risk_note = f"Risk: Îç∞Ïù¥ÌÑ∞ Í≤ÄÏ¶ù Ïã†Ìò∏({len(flags)}Í±¥) Ï°¥Ïû¨, Ï∂îÍ∞Ä ÌôïÏù∏ ÌïÑÏöî."
        else:
            risk_note = "Risk: Îã®Í∏∞ Î≥ÄÎèôÏÑ± ÌôïÎåÄ Íµ¨Í∞Ñ, Ï∂îÏÑ∏ ÌôïÏù∏ ÌïÑÏöî."
            
        return {
            "one_liner": one_liner,
            "numbers": nums,
            "watch_next": watch,
            "risk_note": risk_note
        }

    def _build_evidence_refs(self, topic: Dict, cand_map: Dict) -> List[Dict[str, Any]]:
        """
        Builds detailed evidence references using source candidates.
        """
        refs = []
        numbers = topic.get("numbers", [])
        source_cands = topic.get("source_candidates", [])
        
        for n in numbers[:5]:
            label = n.get("label", "Unknown")
            value = str(n.get("value", "Unknown"))
            
            # Find matching candidate
            matched_cand = None
            for cid in source_cands:
                cand = cand_map.get(cid)
                if not cand: continue
                # Linear search in cand numbers
                for c_num in cand.get("numbers", []):
                    if c_num.get("label") == label: # Heuristic match by label
                         matched_cand = cand
                         break
                if matched_cand: break
            
            # If no match found by label, maybe take the first source? 
            # Risk: might reference wrong source. Safe: explicit "unknown".
            # The constraints say "If source info is missing, explicitly set publisher='unknown'".
            
            publisher = "unknown"
            url = "unknown"
            context = "Extracted from topic numbers"
            
            if matched_cand:
                # Candidate usually has 'article' or 'event' metadata
                # Structure of candidate depends on 'topic_gate_candidates.json' schema
                # Usually: { ..., "article_meta": {"publisher": ...}, "url": ... } or "source_event": {...}
                # Let's support both common patterns in this system
                
                # Pattern 1: Event based
                if "source_event" in matched_cand:
                    evt = matched_cand["source_event"]
                    publisher = evt.get("publisher", "unknown")
                    url = evt.get("url", "unknown")
                    context = evt.get("title", context)
                # Pattern 2: Article/Raw based
                elif "article_meta" in matched_cand:
                     meta = matched_cand["article_meta"]
                     publisher = meta.get("publisher", "unknown")
                     url = matched_cand.get("url", "unknown")
                     context = matched_cand.get("title", context)
                # Fallback: Top level fields
                else:
                    publisher = matched_cand.get("publisher", publisher)
                    url = matched_cand.get("url", url)

            refs.append({
                "label": label,
                "value": value,
                "context": context,
                "source": {
                    "publisher": publisher,
                    "url": url
                }
            })
            
        return refs

    def _compute_flags(self, topic: Dict, evidence_cnt: int) -> List[str]:
        flags = []
        
        # 1. EVIDENCE_TOO_THIN
        if evidence_cnt < 2:
            flags.append("EVIDENCE_TOO_THIN")
            
        # 2. PLACEHOLDER_EVIDENCE
        # Check raw numbers if available
        nums = topic.get("numbers", [])
        for n in nums:
            val = str(n.get("value", "")).lower()
            if "need" in val or "defic" in val or val == "0" or val == "0.0":
                flags.append("PLACEHOLDER_EVIDENCE")
                break
                
        # 3. TITLE_MISMATCH (Simple Heuristic)
        # Check if title keywords appear in reason or evidence labels
        title = topic.get("title", "").lower()
        keywords = [k for k in title.split() if len(k) > 2] # Skip short words
        
        # Collect comparison text
        reasons = " ".join(topic.get("key_reasons", [])).lower()
        ev_labels = " ".join([n.get("label", "") for n in nums]).lower()
        context = reasons + " " + ev_labels
        
        # If significant part of title is missing in context
        # (This is very heuristic, let's just check if ANY keyword matches for now to be safe, 
        # or ALL? "mismatch" implies strong deviation. Let's say if NO keyword matches.)
        if keywords:
            match_found = False
            for k in keywords:
                if k in context:
                    match_found = True
                    break
            if not match_found:
                 flags.append("TITLE_MISMATCH")
                 
        return flags

    def _compute_recommender_tags(self, topic: Dict, flags: List[str]) -> List[str]:
        """Computes recommendation tags (Max 2)."""
        tags = []
        
        # 1. RISK-AWARE
        if flags:
            tags.append("‚ö†Ô∏è RISK-AWARE")
            
        # 2. STRUCTURAL SIGNAL
        # Use simple heuristic if 'matched_axes' not explicitly available in topic json (it's in bridge output)
        # But we can check if key_reasons mentions 'Structural'
        # Or heuristic: if total score > 80 (high confidence) -> might be structural
        # Better: use 'handoff_to_structural' field from Gate
        if topic.get("handoff_to_structural"):
            tags.append("üß† STRUCTURAL SIGNAL")
            
        # 3. TIME-SENSITIVE
        # Heuristic: if 'deadline' or 'D-Day' in title or risk
        # Or simple randomness for demo if no field? No, STRICT HEURISTIC.
        # Check risk_one for 'Short term'
        r1 = topic.get("risk_one", "").lower()
        if "short" in r1 or "imminent" in r1 or "today" in r1:
            tags.append("‚è≥ TIME-SENSITIVE")
            
        # 4. TRENDING NOW
        # If score is very high (top 10%)
        if topic.get("total_score", 0) > 85:
             tags.append("üî• TRENDING NOW")
             
        return tags[:2]

    def _compute_why_today(self, topic: Dict, speak_pack: Dict) -> str:
        """Generates the single line 'Why Today' hint."""
        # Use one-liner from speak pack but simplified
        if speak_pack:
             ol = speak_pack.get("one_liner", "")
             # Extract extraction: "Ïôú ÏßÄÍ∏à: X Ïã†Ìò∏Í∞Ä ÌôïÏù∏ÎêòÏñ¥..." -> "X Ïã†Ìò∏Í∞Ä ÌôïÏù∏ÎêòÏóàÏäµÎãàÎã§."
             # Or just use the reason directly
             return f"{ol.replace('Ïôú ÏßÄÍ∏à: ', '')}"
        return "ÏßÄÍ∏à ÏÑ§Î™Ö Í∞ÄÎä•Ìïú Ï°∞Í±¥ Ï∂©Ï°±"

    def _get_fact_why_now_hint(self, topic: Dict) -> str:
        """Generates template-based 'WHY NOW' hint for FACT-DRIVEN topics."""
        # Predefined Templates
        templates = {
            "FACT_GOV_PLAN": "Ï£ºÏöî Í∏∞Í¥Ä Î∞è Ï†ïÎ∂ÄÏùò Í≥µÏãù ÏßëÌñâ Í≥ÑÌöç Î∞úÌëú",
            "FACT_CORP_DISCLOSURE": "Í∏∞ÏóÖÏùò Í≥µÏãù Í≥µÏãú Î∞è Ïã§Ï†Å Îç∞Ïù¥ÌÑ∞ ÌôïÏù∏",
            "FACT_MACRO_DATA": "ÌïµÏã¨ Í±∞Ïãú ÏßÄÌëúÏùò ÏûÑÍ≥ÑÏπò ÎèåÌåå Î∞è ÏàòÏπòÌôî",
            "FACT_INVEST_FLOW": "ÎåÄÍ∑úÎ™® ÏûêÍ∏à ÌùêÎ¶Ñ Î∞è Ìà¨Ïûê ÏßëÌñâ Îç∞Ïù¥ÌÑ∞ Ìè¨Ï∞©",
            "MARKET_SIZE": "Ï£ºÏöî Î¶¨ÏÑúÏπò Í∏∞Í¥ÄÏù¥ ÏãúÏû• Í∑úÎ™®Î•º Ïû¨ÏÇ∞Ï†ï",
            "OPERATIONAL_START": "Ïã§Ï†ú Ïö¥ÏòÅ Í∞úÏãúÎ°ú Í≤ÄÏ¶ù Îã®Í≥Ñ ÏßÑÏûÖ",
            "REGULATORY_MILESTONE": "Í∑úÏ†ú ÌôòÍ≤Ω Î≥ÄÌôî Î∞è Î≤ïÏ†Å ÎßàÏùºÏä§ÌÜ§ Îã¨ÏÑ±"
        }
        
        # 1. Match by Tags
        tags = topic.get("tags", [])
        for tag in tags:
            if tag in templates:
                return templates[tag]
        
        # 2. Match by Category (metadata)
        category = topic.get("metadata", {}).get("fact_category")
        if category in templates:
            return templates[category]
            
        # 3. Match by Event Type
        event_type = topic.get("event_type", "").upper()
        if event_type in templates:
            return templates[event_type]
            
        return "(explanatory context insufficient)"

    def _check_fact_driven(self, topic: Dict) -> bool:
        """Checks if a topic matches FACT-DRIVEN rules via metadata or tags."""
        if topic.get("is_fact_driven") or topic.get("metadata", {}).get("is_fact_driven"):
            return True
        
        # Check tags for FACT_ prefix
        tags = topic.get("tags", [])
        if any(isinstance(tag, str) and tag.startswith("FACT_") for tag in tags):
            return True
            
        return False

    def _get_eligibility_info(self, status: str, is_fact: bool, flags: List[str], bridge_eligible: bool) -> Dict[str, str]:
        """Maps topic status and flags to a human-readable eligibility badge and reason."""
        is_speakable = False
        if status == "READY":
            is_speakable = True
        elif is_fact and not flags:
            # Fact-driven topics without sanity flags are also speakable
            is_speakable = True
            
        badge = "üéôÔ∏è SPEAKABLE" if is_speakable else "‚è∏Ô∏è NOT SPEAKABLE"
        
        # Reason mapping
        if is_speakable:
            if is_fact:
                reason = "FACT COMPLETE + timing window open"
            else:
                reason = "Evidence sufficient for narration"
        else:
            if bridge_eligible:
                reason = "Structure signal missing"
            elif not flags and status == "HOLD":
                reason = "Signal clarity insufficient"
            elif "EVIDENCE_TOO_THIN" in flags or "WEAK_EVIDENCE" in flags:
                reason = "Evidence insufficient for narration"
            else:
                reason = "Quality below threshold for narration"
                
        return {
            "eligibility_badge": badge,
            "eligibility_reason": reason
        }

    def _calculate_narration_depth(self, topic: Dict, status: str, is_fact: bool, bridge_eligible: bool) -> Dict[str, Any]:
        """Assigns Narration Depth Level based on structural context."""
        why_now = (self._get_fact_why_now_hint(topic) if is_fact else topic.get("key_reasons", [""])[0]).lower()
        title = topic.get("title", "").lower()
        ev_labels = " ".join([n.get("label", "") for n in topic.get("numbers", [])]).lower()
        
        # LEVEL 3 logic (2 of 3)
        # 1) Evidence references specific info (proxy: title/labels look like specific data)
        # 2) WHY NOW ties to company event (proxy: 'company', 'corp', 'contract' in why now)
        # 3) FACT-DRIVEN + Bridge eligible OR READY with multi-layer evidence
        cond1 = any(x in ev_labels or x in title for x in ["revenue", "order", "contract", "dominance", "market share"])
        cond2 = any(x in why_now for x in ["company", "corp", "firm", "capability"])
        cond3 = (is_fact and bridge_eligible) or (status == "READY" and len(topic.get("numbers", [])) >= 3)
        
        score_v3 = sum([cond1, cond2, cond3])
        if score_v3 >= 2:
            return {
                "narration_level": 3,
                "narration_badge": "üé§ LEVEL 3",
                "narration_helper": "Stock names can be mentioned"
            }
            
        # LEVEL 2 logic (ALL apply)
        # 1) WHY NOW references industry/sector
        # 2) Evidence includes sector metrics (proxy: high level but sector-ish)
        # 3) Value flow without naming company
        is_sector_why = any(x in why_now for x in ["sector", "industry", "market size", "segments"])
        is_sector_ev = any(x in ev_labels for x in ["units", "output", "demand", "supply"])
        
        if is_sector_why and is_sector_ev:
            return {
                "narration_level": 2,
                "narration_badge": "üé§ LEVEL 2",
                "narration_helper": "Sector-level discussion possible"
            }
            
        # LEVEL 1 - Default
        return {
            "narration_level": 1,
            "narration_badge": "üé§ LEVEL 1",
            "narration_helper": "Macro explanation only"
        }

    def _get_ceiling_reason(self, level: int, is_fact: bool) -> str:
        """Determines the reason why narration level is limited to 1 or 2."""
        if level == 3:
            return None
            
        if is_fact and level in [1, 2]:
            return "Í≥µÏãù ÏàòÏπòÎäî Ï°¥Ïû¨ÌïòÎÇò ÏàòÌòú Í∑ÄÏÜç Î∂àÎ™ÖÌôï"
            
        if level == 1:
            return "ÏÇ∞ÏóÖ ÎòêÎäî Í∏∞ÏóÖ Ïó∞Í≤∞ Ïã†Ìò∏ ÏóÜÏùå"
        if level == 2:
            return "ÌäπÏ†ï Í∏∞ÏóÖÏùò Íµ¨Ï°∞Ï†Å Ïö∞ÏúÑ Ï¶ùÍ±∞ Î∂ÄÏ°±"
            
        return None

    def _render_promotion_requirements(self, level: int, is_fact: bool, lines: List[str]):
        """Renders the Promotion to Level 3 Requirements block (Display Only)."""
        if level >= 3:
            return
            
        lines.append(f"\n**PROMOTION TO LEVEL 3 REQUIRES**:")
        
        if is_fact:
            lines.append(f"NOTE: \"Official figures exist, but attribution to specific beneficiaries is not yet verified.\"")
            
        lines.append(f"- [ ] Company-level earnings or guidance confirmation")
        lines.append(f"- [ ] Contract / order / disclosure-level evidence")
        lines.append(f"- [ ] Capital signal (ownership, buyback, investment)")
        lines.append(f"- [ ] Structural advantage vs competitors")

    def _build_judgment_notes(self, t: Dict) -> List[str]:
        """Surfaces narrative risks based on internal inconsistencies (Step 13)."""
        notes = []
        
        # A) FACT ‚Üî WHY NOW Consistency
        if t.get("is_fact_driven"):
            why_now = t.get("fact_why_now", "")
            if "(explanatory context insufficient)" in why_now:
                notes.append("WHY NOW explanation is too generic for a FACT-based topic.")
                
        # B) LEVEL ‚Üî Evidence Depth Mismatch
        if t.get("narration_level") == 3 and t.get("evidence_count", 0) < 3:
            notes.append("LEVEL 3 assigned, but evidence depth is shallow.")
            
        # C) Speakable ‚Üî Risk Tension
        is_ready = t.get("status") == "READY"
        flags = t.get("flags", [])
        if is_ready:
            if len(flags) >= 2 or t.get("narration_ceiling") is not None:
                notes.append("Speakable status conflicts with elevated narrative risk.")
                
        return notes if notes else None

    def _build_selection_rationale(self, t: Dict) -> List[str]:
        """Explains why a READY topic was selected (Step 14)."""
        rationale = []
        
        # 1. PRIMARY DRIVER
        if t.get("is_fact_driven"):
            rationale.append("Primary: Í≥µÏãù Ìå©Ìä∏ Í∏∞Î∞ò ÌÜ†ÌîΩÏù¥ÎÇò Íµ¨Ï°∞ Ïã†Ìò∏ÏôÄ Í≤∞Ìï©")
        else:
            rationale.append("Primary: Íµ¨Ï°∞Ï†Å Ïù¥ÏÉÅÏßïÌõÑÍ∞Ä Ìå©Ìä∏/Îâ¥Ïä§Î≥¥Îã§ ÏÑ†Ìñâ")
            
        # 2. TIMING (Heuristic based on existing fields)
        why_now = t.get("why_today", "").lower()
        r1 = t.get("risk_one", "").lower()
        if "deadline" in why_now or "event" in why_now or "today" in why_now or "short" in r1:
            rationale.append("Timing: ÏùºÏ†ï Í∏∞Î∞ò Ïù¥Î≤§Ìä∏ÏôÄ ÏãúÏ†ê ÏùºÏπò")
        else:
            rationale.append("Timing: ÎàÑÏ†Å Ïã†Ìò∏Í∞Ä ÏûÑÍ≥ÑÏπò ÎèÑÎã¨")
            
        # 3. RELATIVE SELECTION
        rationale.append("Relative: ÎèôÏ¢Ö ÌÜ†ÌîΩ ÎåÄÎπÑ Í∑ºÍ±∞ Î∞ÄÎèÑ Ïö∞ÏúÑ")
        
        # 4. NARRATION RANGE
        lvl = t.get("narration_level", 1)
        if lvl == 3:
            rationale.append("Narration: Í∞úÎ≥Ñ Ï¢ÖÎ™© Ïñ∏Í∏â Í∞ÄÎä• (Ï∂îÏ≤ú ÏïÑÎãò)")
        elif lvl == 2:
            rationale.append("Narration: ÏÑπÌÑ∞ Îã®ÏúÑÍπåÏßÄ ÏÑ§Î™Ö Í∞ÄÎä•")
        else:
            rationale.append("Narration: Îß§ÌÅ¨Î°ú ÏàòÏ§Ä ÏÑ§Î™ÖÏóê Ï†ÅÌï©")
            
        # 5. CONSTRAINT (optional)
        ceiling = t.get("narration_ceiling")
        j_notes = t.get("judgment_notes", [])
        if ceiling or j_notes:
            constraint_text = ceiling if ceiling else (j_notes[0] if j_notes else "")
            if constraint_text:
                rationale.append(f"Constraint: {constraint_text}")
                
        return rationale

    def _get_contrast_rationale(self, c: DecisionCard, competitors: List[DecisionCard]) -> Dict[str, Any]:
        """Builds comparative logic: Why this topic won over others (Step 15)."""
        if not competitors:
            return None
            
        # 1. Build Contrast Set (Step 15-1)
        # Filter: Same lane or same/adjacent level
        filtered = [
            comp for comp in competitors 
            if comp.is_fact_driven == c.is_fact_driven or abs(comp.narration_level - c.narration_level) <= 1
        ]
        
        if not filtered:
            return None
            
        # Pick top 2 by score (they are already sorted in ranked, but let's be safe if cards list isn't)
        # Using status == HOLD as identifying mark.
        competitors_set = sorted(filtered, key=lambda x: 0, reverse=True)[:2] # Score not explicitly in Card, but list is ordered
        # Wait, DecisionCard needs score if I want to sort here. Or I trust the order from ranked.
        # Let's assume order is preserved in cards list.
        
        # 2. Contrast Rules (Step 15-2)
        selected_reason = "Better timing alignment"
        
        # Check reasons in priority order
        # a) Higher Evidence Density (if significant difference)
        # Using a simple threshold (e.g., +2 more items) or just "more" items? 
        # Requirement says "Higher evidence density". Let's say strictly >
        max_comp_ev = max([comp.evidence_count for comp in competitors_set]) if competitors_set else 0
        if c.evidence_count > max_comp_ev + 1: # Significant difference
            selected_reason = "Higher evidence density"
        # b) Broader Narration Range (Higher Priority than Density? Or overrides?)
        # Let's check Level.
        elif c.narration_level > max([comp.narration_level for comp in competitors_set]):
            selected_reason = "Broader narration range"
            
        rejections = []
        for comp in competitors_set:
            reason = "Evidence too thin"
            if comp.judgment_notes:
                if any("WHY NOW" in n for n in comp.judgment_notes):
                    reason = "Missing WHY NOW"
                elif any("risk" in n.lower() for n in comp.judgment_notes):
                    reason = "Narrative risk flagged"
            elif comp.narration_ceiling:
                reason = "Ceiling constraint"
            
            rejections.append({
                "topic_id": comp.topic_id,
                "reason": reason
            })
            
        return {
            "selected_reason": selected_reason,
            "rejections": rejections
        }

    def _render_sanity_panel(self, data: Dict[str, Any], lines: List[str]):
        """Renders the SYSTEM STATUS panel at the top."""
        lines.append("### üè• SYSTEM STATUS (Today)")
        lines.append(f"- **Topics Generated**: {data.get('total_topics', 0)}")
        s = data.get("summary", {})
        lines.append(f"- **READY / HOLD / DROP**: {s.get('READY', 0)} / {s.get('HOLD', 0)} / {s.get('DROP', 0)}")
        lines.append(f"- **FACT-DRIVEN / ANOMALY-DRIVEN**: {data.get('fact_driven_count', 0)} / {data.get('anomaly_driven_count', 0)}")
        
        js = data.get("judgment_summary", {})
        if any(v > 0 for v in js.values()):
            lines.append("\n**JUDGMENT WARNINGS TODAY**")
            lines.append(f"- Weak Timing: {js.get('weak_timing', 0)}")
            lines.append(f"- Shallow Evidence: {js.get('shallow_evidence', 0)}")
            lines.append(f"- Narrative Risk: {js.get('narrative_risk', 0)}")
        lines.append("")

    def _render_drift_warnings(self, data: Dict[str, Any], lines: List[str]):
        """Renders Drift Warning Indicators (Operational Safety)."""
        warnings = []
        flags = data.get("flag_summary", {})
        s = data.get("summary", {})
        
        # 1. TITLE-TO-EVIDENCE DRIFT
        if flags.get("TITLE_MISMATCH", 0) >= 2:
            warnings.append({
                "badge": "‚ö†Ô∏è TITLE-TO-EVIDENCE DRIFT",
                "explanation": "ÌÜ†ÌîΩ Ï†úÎ™©Í≥º Í∏∞Î∞ò Îç∞Ïù¥ÌÑ∞ Í∞ÑÏùò Í±∞Î¶¨Í∞Ä Î©ÄÏñ¥ÏßÄÍ≥† ÏûàÏúºÎãà, ÏóîÏßÑÏùò Ï†úÎ™© Ï∂îÏ∂ú Î°úÏßÅ Ï†êÍ≤ÄÏù¥ Í∂åÏû•Îê©ÎãàÎã§."
            })
            
        # 2. EVIDENCE THINNING
        thin_count = flags.get("PLACEHOLDER_EVIDENCE", 0) + flags.get("EVIDENCE_TOO_THIN", 0)
        if thin_count >= 2:
            warnings.append({
                "badge": "‚ö†Ô∏è EVIDENCE THINNING",
                "explanation": "Í∏∞Î∞ò Îç∞Ïù¥ÌÑ∞Ïùò ÏàòÏπò Ï†ïÎ≥¥Í∞Ä ÌèâÏÜåÎ≥¥Îã§ Î∂ÄÏ°±ÌïòÍ≤å ÏàòÏßëÎêòÍ≥† ÏûàÏúºÎãà, Îç∞Ïù¥ÌÑ∞ ÏÜåÏä§ ÏïàÏ†ïÏÑ±ÏùÑ ÌôïÏù∏ÌïòÏãúÍ∏∞ Î∞îÎûçÎãàÎã§."
            })
            
        # 3. SPEAK DROUGHT
        if s.get("READY", 0) == 0 and data.get("candidates_count", 0) >= 3:
            warnings.append({
                "badge": "‚ö†Ô∏è SPEAK DROUGHT",
                "explanation": "Ï∂©Î∂ÑÌïú ÌõÑÎ≥¥Í∞Ä ÏÉùÏÑ±ÎêòÏóàÏúºÎÇò ÎÇ¥Î†àÏù¥ÏÖò Í∏∞Ï§ÄÏùÑ ÌÜµÍ≥ºÌïòÏßÄ Î™ªÌñàÏäµÎãàÎã§. ÌíàÏßà Í∏∞Ï§ÄÏùÑ Ïû¨Í≤ÄÌÜ†ÌïòÍ±∞ÎÇò Îç∞Ïù¥ÌÑ∞ ÏÜåÏä§Î•º ÌôïÏû•Ìï† ÏãúÏ†êÏûÖÎãàÎã§."
            })
            
        # 4. FACT OVERDOMINANCE
        total = data.get("total_topics", 0)
        if total > 0 and (data.get("fact_driven_count", 0) / total) > 0.7:
            warnings.append({
                "badge": "‚ö†Ô∏è FACT OVERDOMINANCE",
                "explanation": "ÏãúÏä§ÌÖúÏù¥ Î¶¨Ìè¨Ìä∏ Í∏∞Î∞òÏùò Ìå©Ìä∏Ïóê Í≥ºÌïòÍ≤å ÏπòÏ§ëÌï¥ ÏûàÏäµÎãàÎã§. Ïã§ÏãúÍ∞Ñ ÏãúÍ∑∏ÎÑê(Anomaly) ÌÉêÏßÄ ÏóîÏßÑÏùò ÏûëÎèô Ïó¨Î∂ÄÎ•º Ï†êÍ≤ÄÌï¥ Î≥¥ÏãúÍ∏∞ Î∞îÎûçÎãàÎã§."
            })
            
        if warnings:
            lines.append("#### üö® DRIFT MONITOR")
            for w in warnings:
                lines.append(f"**{w['badge']}**")
                lines.append(f"> {w['explanation']}")
            lines.append("")
        else:
            lines.append("‚úÖ **SYSTEM HEALTH**: All clear (Operational margins normal)")
            lines.append("")

    def _render_portfolio_balance(self, lines: List[str], snapshot: Dict[str, Any], assessment: Dict[str, Any]):
        """Renders the PORTFOLIO BALANCE block (Step 16)."""
        lines.append(f"üìä **PORTFOLIO BALANCE (Today)**")
        
        # Composition
        comp = []
        if snapshot['fact_count'] > 0: comp.append(f"FACT {snapshot['fact_count']}")
        if snapshot['anomaly_count'] > 0: comp.append(f"ANOMALY {snapshot['anomaly_count']}")
        lines.append(f"- Composition: {' / '.join(comp)}")
        
        # Depth
        depth = []
        for l in [1, 2, 3]:
            cnt = snapshot['level_counts'].get(l, 0)
            if cnt > 0: depth.append(f"L{l} {cnt}")
        lines.append(f"- Depth: {' ¬∑ '.join(depth)}")
        
        # Timing
        timing = snapshot.get('timing_tags', [])
        lines.append(f"- Timing: {' ¬∑ '.join(timing) if timing else '(None)'}")
        
        # Assessment
        status = assessment.get("status", "Unknown")
        reason = assessment.get("reason", "")
        lines.append(f"- Assessment: {status} ‚Äî {reason}")
        lines.append("")

    def _build_portfolio_snapshot(self, cards: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Aggregates portfolio stats from READY topics (Step 16-1)."""
        # cards are dicts when coming from render_markdown(data)
        ready_cards = [c for c in cards if c.get('status') == 'READY']
        
        # Lane
        fact_cnt = len([c for c in ready_cards if c.get('is_fact_driven')])
        anomaly_cnt = len(ready_cards) - fact_cnt
        
        # Level
        lvl_counts = {1: 0, 2: 0, 3: 0}
        for c in ready_cards:
            l = c.get('narration_level', 1)
            lvl_counts[l] = lvl_counts.get(l, 0) + 1
            
        # Timing Tags
        # Filter for specific timing tags: TIME-SENSITIVE, STRUCTURAL, TRENDING NOW
        target_tags = ["TIME-SENSITIVE", "STRUCTURAL SIGNAL", "TRENDING NOW"] 

        found_tags = set()
        for c in ready_cards:
            tags = c.get('tags') or []
            for t in tags:
                for target in target_tags:
                    if target in t:
                        found_tags.add(target)
                        
        return {
            "total_ready": len(ready_cards),
            "fact_count": fact_cnt,
            "anomaly_count": anomaly_cnt,
            "level_counts": lvl_counts,
            "timing_tags": sorted(list(found_tags))
        }

    def _assess_portfolio_balance(self, snapshot: Dict[str, Any]) -> Dict[str, str]:
        """Applies balance rules (Step 16-2)."""
        total = snapshot["total_ready"]
        if total == 0:
            return {"status": "Empty", "reason": "No READY topics"}
            
        # 1. Fact Ratio <= 60%
        fact_ratio = snapshot["fact_count"] / total
        if fact_ratio > 0.6:
            return {"status": "Concentrated", "reason": "FACT-heavy"}
            
        # 2. L3 <= 2
        if snapshot["level_counts"][3] > 2:
            return {"status": "Concentrated", "reason": "Stock-heavy"}
            
        # 3. Timing Diversity >= 2
        # Constraint: "At least 2 different Timing tags present"
        # Interpreted as: across the portfolio, we cover at least 2 distinct timing angles.
        if len(snapshot["timing_tags"]) < 2:
            # Reason: Single-theme risk? 
            # Prompt says "Single-theme risk".
            return {"status": "Concentrated", "reason": "Single-theme risk"}
            
        return {"status": "Balanced", "reason": "Portfolio mix optimal"}

    def save_snapshot(self, ymd: str, data: Dict[str, Any]) -> Path:
        """
        Saves the dashboard data to daily_lock.json for immutable reference.
        Path: data/topics/gate/{ymd}/daily_lock.json
        """
        gate_dir = self.base_dir / "data" / "topics" / "gate" / ymd.replace("-", "/")
        if not gate_dir.exists():
            gate_dir.mkdir(parents=True, exist_ok=True)
            
        lock_path = gate_dir / "daily_lock.json"
        lock_path.write_text(json.dumps(data, indent=2, ensure_ascii=False), encoding="utf-8")
        return lock_path

    def _determine_impact_window(self, topic: Dict[str, Any], tags: List[str]) -> Tuple[str, str]:
        """Determines Time-to-Impact Window (Step 17)."""
        tags = tags or []
        risk_one = topic.get("risk_one", "")
        reasons = topic.get("key_reasons", [])
        combined_text = (risk_one + " " + " ".join(reasons)).lower()
        
        # 1. Explicit Schedule -> IMMEDIATE
        # Regex-like keywords
        schedule_keywords = ["d-day", "today", "tomorrow", "scheduled", "timeline", "ÌôïÏ†ï", "Î∞úÌëúÏùº"]
        if any(k in combined_text for k in schedule_keywords):
            return "IMMEDIATE", "Ïù¥Ïäà Î∞òÏòÅÏù¥ Ïù¥ÎØ∏ ÏãúÏûëÎê®"
            
        # 2. TIME-SENSITIVE -> NEAR
        if any("TIME-SENSITIVE" in t for t in tags):
            # Also check if it's actually immediate if risk says so, but priority rule says TIME-SENSITIVE -> NEAR
            # unless caught by #1. Strict priority.
            return "NEAR", "Îã®Í∏∞ Îâ¥Ïä§/Ïù¥Î≤§Ìä∏ Ïó∞Îèô"
            
        # 3. TRENDING NOW -> MID
        if any("TRENDING NOW" in t for t in tags):
             return "MID", "ÎàÑÏ†Å ÌôïÏù∏ Íµ¨Í∞Ñ"
             
        # 4. STRUCTURAL -> LONG
        if any("STRUCTURAL" in t for t in tags):
             return "LONG", "Íµ¨Ï°∞Ï†Å Î≥ÄÌôî Í¥ÄÏ†ê"
             
        # 5. Fallback -> MID
        return "MID", "ÎàÑÏ†Å ÌôïÏù∏ Íµ¨Í∞Ñ(Inferred)"

    def _get_operator_badge(self, topic_id: str, decisions_map: Dict[str, Dict]) -> str:
        """Step 40: Returns visual feedback badge if decision exists."""
        d = decisions_map.get(topic_id)
        if not d: return ""
        action = d.get("operator_action", "")
        return f"| üß≠ **OPERATOR: {action.replace('_', ' ')}**"

    def _render_operator_summary(self, lines: List[str], decisions_map: Dict[str, Dict]):
        """Step 40: Daily Operator Summary Panel."""
        from src.ops.operator_decision_log import OPERATOR_ACTION_ENUM
        counts = {
            OPERATOR_ACTION_ENUM.PICKED_FOR_CONTENT: 0,
            OPERATOR_ACTION_ENUM.SKIPPED_TODAY: 0,
            OPERATOR_ACTION_ENUM.DEFERRED: 0,
            OPERATOR_ACTION_ENUM.REJECTED: 0
        }
        for d in decisions_map.values():
            action = d.get("operator_action")
            if action in counts:
                counts[action] += 1
        
        if not any(counts.values()): return
        
        lines.append("\n#### üèõÔ∏è OPERATOR DECISIONS (TODAY)")
        for action, count in counts.items():
            if count > 0:
                lines.append(f"- **{action}**: {count}")

    def _render_ready_action_bar(self, lines: List[str], topic_id: str, title: str):
        """Step 40: Placeholder for READY action bar."""
        lines.append(f"> **ACTION**: [ Pick ] [ Skip Today ] [ Defer ] [ Reject ]")

    def _render_shadow_action_bar(self, lines: List[str], topic_id: str, title: str):
        """Step 40: Placeholder for SHADOW action bar."""
        lines.append(f"    > **ACTION**: [ Defer ] [ Reject ]")

    def _render_correlation_panel(self, lines: List[str], data: Dict[str, Any]):
        """Step 41: Correlation Summary Scoreboard."""
        summary = data.get("summary", {})
        lines.append("\n#### üìå PICK ‚Üí OUTCOME (Last 30d)")
        lines.append(f"- Picked: {summary.get('picked', 0)} | ‚úÖ Confirmed: {summary.get('confirmed', 0)} | ‚ùå Failed: {summary.get('failed', 0)} | ‚è≥ Unresolved: {summary.get('unresolved', 0)} | ? Missing: {summary.get('missing', 0)}")
        
        rows = data.get("rows", [])
        if not rows:
            lines.append("- _No human picks in last 30d._")
        else:
            lines.append("\n**Recent Picks**")
            for r in rows[:10]: # Last 10
                outcome = r.get("outcome", "MISSING")
                icon = "‚è≥"
                if outcome == "CONFIRMED": icon = "‚úÖ"
                elif outcome == "FAILED": icon = "‚ùå"
                elif outcome == "MISSING": icon = "?"
                
                lines.append(f"- [{r['pick_date']}] {r['topic_title']} ‚Äî {icon} {outcome}")
        
        errors = data.get("errors", [])
        if errors:
            lines.append(f"\n> ‚ö†Ô∏è Correlation warnings: {len(errors)}")

    def _render_auto_priority_panel(self, lines: List[str], data: Dict[str, Any]):
        """Step 43: Daily Auto-Priority Summary Panel."""
        top_candidates = data.get("top_candidates", [])
        lines.append("\n#### üî• AUTO-PICK PRIORITY (Top 3‚Äì5)")
        
        if not top_candidates or len(top_candidates) < 3:
            lines.append("- _Insufficient data for auto-prioritization._")
            return
            
        for i, c in enumerate(top_candidates, 1):
            score = c.get("priority_score", 0)
            
            badge = "‚ö™ LOW"
            if score >= 8: badge = "üî¥ CRITICAL"
            elif score >= 5: badge = "üü† HIGH"
            elif score >= 3: badge = "üü¢ MODERATE"
            
            factors = ", ".join(c.get("reason_factors", []))
            lines.append(f"{i}. **{c['title']}** ({badge} | Score: {score})")
            if factors:
                lines.append(f"   - *Factors*: {factors}")

    def _generate_auto_priority(self, ymd: str, ready_candidates: List[Dict], shadow_pool: Dict[str, Any]) -> Dict[str, Any]:
        """Runs the auto prioritizer and returns the result."""
        from src.ops.auto_prioritizer import AutoPrioritizer
        prioritizer = AutoPrioritizer(self.base_dir)
        return prioritizer.run(ymd, ready_candidates, shadow_pool.get("candidates", []))

    def _render_auto_approved_panel(self, lines: List[str], data: Dict[str, Any]):
        """Step 44: Daily Auto-Approval Summary Panel."""
        approved = data.get("auto_approved", [])
        lines.append("\n#### ü§ñ AUTO-APPROVED TOPICS")
        
        bundle_md = data.get("bundle_md")
        if bundle_md:
            lines.append(f"> üì¶ **SPEAK BUNDLE**: [{Path(bundle_md).name}](file:///{self.base_dir / bundle_md})")
            
            # Step 47: Skeleton Status
            sk_idx_path = self.base_dir / bundle_md.replace("speak_bundle.md", "skeletons/skeleton_index.json")
            if sk_idx_path.exists():
                try:
                    sk_idx = json.loads(sk_idx_path.read_text(encoding="utf-8"))
                    lines.append(f"> üß± **SCRIPT SKELETONS**: available (short: {sk_idx.get('count_short', 0)}, long: {sk_idx.get('count_long', 0)})")
                except:
                    lines.append(f"> üß± **SCRIPT SKELETONS**: available (index error)")
            else:
                lines.append(f"> üß± **SCRIPT SKELETONS**: not generated")

        if not approved:
            lines.append("- _No topics met strict auto-approval conditions today._")
            return
            
        from src.ops.production_format_router import ProductionFormatRouter
        router = ProductionFormatRouter()
        
        for a in approved:
            # We need to map 'a' to a format. 'a' has priority_score, title, etc.
            # But route_topic expects narration_level, etc. 
            # Actually, the dashboard already has the topic data in 'cards'.
            # However, _render_auto_approved_panel only gets the summary 'data'.
            # Let's simple-map if possible or just use the badge from a pre-calculated field if I added it.
            # Step 46-5 says "Add small badge".
            
            reasons = ", ".join([f"`{r}`" for r in a.get("approval_reason", [])])
            
            # Simple heuristic for dashboard if full topic data isn't here, 
            # but ideally we want the real router result.
            # Let's assume the bundle exporter hasn't run yet or we want inline calculation.
            # Actually, the dashboard is often rendered AFTER the engine runs the ops.
            # But here we are IN the dashboard renderer.
            
            # Let's use a very simplified version for the dashboard badge if we don't have the full object,
            # OR pass the format info in the auto_approved_today.json.
            # Step 46-3 says "Attach routing result to speak_bundle.json/md".
            # It doesn't explicitly say auto_approved_today.json.
            # Let's update AutoApprovalGate to include the format or just calculate here.
            
            score = a.get("priority_score", 0)
            fmt_badge = "üé¨ SHORT"
            if score >= 10: fmt_badge = "üé• LONG"
            elif score >= 8: fmt_badge = "üé¨+üé• BOTH"
            
            lines.append(f"- **{a['title']}** (üü¢ **AUTO-APPROVED** üîí | {fmt_badge} | Score: {score})")
            if reasons:
                lines.append(f"   - *Reasons*: {reasons}")
